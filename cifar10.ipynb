{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dcc1d28-3173-4f54-9dc9-d29254c55630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import shutil\n",
    "import pickle\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "from utils.utils import ensure_dir, read_json, informal_log\n",
    "from utils.visualizations import plot\n",
    "from utils.model_utils import prepare_device\n",
    "\n",
    "import model.metric as module_metric\n",
    "import model.loss as module_loss\n",
    "import datasets.datasets as module_data\n",
    "\n",
    "from train import main as train_fn\n",
    "from predict import predict\n",
    "from parse_config import ConfigParser\n",
    "\n",
    "\n",
    "sys.path.insert(0, 'setup')\n",
    "from setup_cifar10 import setup_cifar10 \n",
    "# import cv2\n",
    "# print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfa6fe07-4acc-45b4-ba52-40fbdf2dddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_save_dir = os.path.join('saved', 'cifar10')\n",
    "processed_cifar_dir = 'data/cifar10-processed'\n",
    "\n",
    "ensure_dir(cifar10_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3310577-8b85-4f07-bc15-802d465dbf3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Process CIFAR-10 to get rid of bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b13a684-9587-4128-abe3-ec2f16bcde46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 already processed at data/cifar10-processed\n"
     ]
    }
   ],
   "source": [
    "raw_cifar_dir = 'data/cifar-10-batches-py'\n",
    "\n",
    "if not os.path.exists(processed_cifar_dir):\n",
    "    setup_cifar_10(\n",
    "        raw_cifar_dir=raw_cifar_dir,\n",
    "        processed_cifar_dir=processed_cifar_dir)\n",
    "    print(\"Processing CIFAR10\")\n",
    "else:\n",
    "    print(\"CIFAR-10 already processed at {}\".format(processed_cifar_dir))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae95cefb-d320-4f26-a8c8-795e825fa22c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Datasets for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da7e3f0f-9536-43f6-b3f0-f9bc98586399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from utils.visualizations import show_image\n",
    "\n",
    "class CIFAR10Dataset():\n",
    "    def __init__(self,\n",
    "                 cifar_dir, \n",
    "                 split):\n",
    "                 # normalize=False,\n",
    "                 # means=[0.4914, 0.4822, 0.4465],\n",
    "                 # stds=[0.2471, 0.2435, 0.2616]):\n",
    "        \n",
    "        assert split in ['train', 'test'], \"Invalid split '{}'. Must be 'train' or 'test'\".format(split)\n",
    "        if split == 'train':\n",
    "            files = ['data_batch_{}'.format(i) for i in range(1,6)]\n",
    "        else:\n",
    "            files = ['test_batch']\n",
    "            \n",
    "        images = []\n",
    "        labels = []\n",
    "        for file in files:\n",
    "            path = os.path.join(cifar_dir, file)\n",
    "            data = pickle.load(open(path, 'rb'))\n",
    "            cur_images = data['data']\n",
    "            cur_images = np.reshape(cur_images, (-1, 3, 32, 32))\n",
    "            images.append(cur_images)\n",
    "            \n",
    "            cur_labels = np.array(data['labels'])\n",
    "            labels.append(cur_labels)\n",
    "        \n",
    "        self.images = np.concatenate(images, axis=0)\n",
    "        self.images = np.transpose(self.images, (0, 2, 3, 1)) # N x H x W x C\n",
    "        \n",
    "#         if normalize:\n",
    "#             means = np.tile(means, (*self.images.shape[:3], 1))\n",
    "#             stds = np.tile(stds, (*self.images.shape[:3], 1))\n",
    "            \n",
    "#             self.images = (self.images - means) / stds\n",
    "#             print(means.shape)\n",
    "#             print(means[0, :, 0, 0])\n",
    "            # self.images = \n",
    "        self.labels = np.concatenate(labels, axis=0)\n",
    "        self.n_samples = len(self.labels)\n",
    "        \n",
    "    def get_images(self):\n",
    "        return self.images\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "train_dataset = CIFAR10Dataset(\n",
    "    cifar_dir=processed_cifar_dir,\n",
    "    split='train')\n",
    "        \n",
    "train_images = train_dataset.get_images()\n",
    "train_labels = train_dataset.get_labels()\n",
    "\n",
    "test_dataset = CIFAR10Dataset(\n",
    "    cifar_dir=processed_cifar_dir,\n",
    "    split='test')\n",
    "test_images = test_dataset.get_images()\n",
    "test_labels = test_dataset.get_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777b7d9-c9e5-4ef5-b2b2-ee8b63989c83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### CIFAR10 dataset for torch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1421ffbb-aed0-40b4-8ed2-d4e4a16ba029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10TorchDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 cifar_dir,\n",
    "                 split,\n",
    "                 to_tensor=True,\n",
    "                 normalize=True,\n",
    "                 means=[0.4914, 0.4822, 0.4465],\n",
    "                 stds=[0.2471, 0.2435, 0.2616]):\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        assert split in ['train', 'test'], \"Invalid split '{}'. Must be 'train' or 'test'\".format(split)\n",
    "        if split == 'train':\n",
    "            files = ['data_batch_{}'.format(i) for i in range(1,6)]\n",
    "        else:\n",
    "            files = ['test_batch']\n",
    "            \n",
    "        for file in files:\n",
    "            path = os.path.join(cifar_dir, file)\n",
    "            data = pickle.load(open(path, 'rb'))\n",
    "            cur_images = data['data']\n",
    "            cur_images = np.reshape(cur_images, (-1, 3, 32, 32))\n",
    "            images.append(cur_images)\n",
    "            \n",
    "            cur_labels = np.array(data['labels'])\n",
    "            labels.append(cur_labels)\n",
    "        \n",
    "        self.images = np.concatenate(images, axis=0)\n",
    "        self.images = np.transpose(self.images, (0, 2, 3, 1))\n",
    "        self.labels = np.concatenate(labels, axis=0)\n",
    "        self.n_samples = len(self.labels)\n",
    "                \n",
    "        # Create transformations\n",
    "        self.transforms = [transforms.ToTensor()]  # changes dims H x W x C -> C x H x W and scales to [0, 1]\n",
    "        if normalize:\n",
    "            self.transforms.append(transforms.Normalize(means, stds))\n",
    "        self.transforms = transforms.Compose(self.transforms)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transforms(self.images[idx])\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        \n",
    "train_dataset = CIFAR10(\n",
    "    cifar_dir=processed_cifar_dir,\n",
    "    split='train',\n",
    "    to_tensor=False,\n",
    "    normalize=False)\n",
    "\n",
    "test_dataset = CIFAR10(\n",
    "    cifar_dir=processed_cifar_dir,\n",
    "    split='test',\n",
    "    to_tensor=False,\n",
    "    normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b47e24-a19a-4197-bcd2-df770575f29b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### OpenCV's SIFT\n",
    "Tutorial from [here](https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "529e4009-d577-4221-847a-2487f0df2769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating keypoints and feature descriptors for CIFAR-10 train split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 50000/50000 [03:11<00:00, 260.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating keypoints and feature descriptors for CIFAR-10 test split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:38<00:00, 257.68it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_FEATURES = 32\n",
    "RESIZE = (128, 128)\n",
    "descriptor_size = 128\n",
    "debug = False\n",
    "\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "train_keypoints = []\n",
    "train_descriptors = []\n",
    "\n",
    "images = {\n",
    "    'train': train_images,\n",
    "    'test': test_images\n",
    "}\n",
    "sift_data = {\n",
    "    'train': {\n",
    "        'keypoints': [],\n",
    "        'descriptors': []\n",
    "    },\n",
    "    'test': {\n",
    "        'keypoints': [],\n",
    "        'descriptors': []\n",
    "    }\n",
    "}\n",
    "for split in ['train', 'test']:\n",
    "    print(\"Calculating keypoints and feature descriptors for CIFAR-10 {} split\".format(split))\n",
    "    split_images = images[split]\n",
    "    split_keypoints = sift_data[split]['keypoints']\n",
    "    split_descriptors = sift_data[split]['descriptors']\n",
    "    for idx, image in enumerate(tqdm(split_images, total=len(split_images))):\n",
    "        if debug and idx == 5:\n",
    "            break\n",
    "        # Image processing\n",
    "        image = cv2.resize(image, RESIZE)\n",
    "        image_bw = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calculate descriptors\n",
    "        keypoints, descriptors = sift.detectAndCompute(image_bw, None)\n",
    "        if debug:\n",
    "            img2 = cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=0)\n",
    "            plt.imshow(img2)\n",
    "            plt.show()\n",
    "        if len(keypoints) == 0:\n",
    "            descriptors = np.zeros((1, descriptor_size), np.float32)\n",
    "        keypoint_objs = []\n",
    "        for keypoint in keypoints:\n",
    "            keypoint_objs.append({\n",
    "                'point': keypoint.pt,\n",
    "                'size': keypoint.size,\n",
    "                'angle': keypoint.angle,\n",
    "                'response': keypoint.response,\n",
    "                'octave': keypoint.octave,\n",
    "                'class_id': keypoint.class_id\n",
    "            })\n",
    "        split_keypoints.append(keypoint_objs)\n",
    "        split_descriptors.append(descriptors)\n",
    "        \n",
    "    sift_data[split]['keypoints'] = split_keypoints\n",
    "    sift_data[split]['descriptors'] = split_descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ef880c6-32f2-4fce-a916-15a3dd81a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved keypoints & descriptors from train and test to saved/cifar10/sift_128_128/sift_keypoints_descriptors.pth\n"
     ]
    }
   ],
   "source": [
    "assert len(sift_data['test']['keypoints']) == len(test_images)\n",
    "assert len(sift_data['test']['descriptors']) == len(test_images)\n",
    "assert len(sift_data['train']['keypoints']) == len(train_images)\n",
    "assert len(sift_data['train']['descriptors']) == len(train_images)\n",
    "# assert \n",
    "sift_save_path = os.path.join(cifar10_save_dir, \n",
    "                              'sift_{}_{}'.format(RESIZE[0], RESIZE[1]), \n",
    "                              'sift_keypoints_descriptors.pth')\n",
    "ensure_dir(os.path.dirname(sift_save_path))\n",
    "if not os.path.exists(sift_save_path):\n",
    "    torch.save(sift_data, sift_save_path)\n",
    "    print(\"Saved keypoints & descriptors from train and test to {}\".format(sift_save_path))\n",
    "else:\n",
    "    print(\"Path {} already exists\".format(sift_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8378c66e-79ab-44a5-8bbf-8fd8d2b633f0",
   "metadata": {},
   "source": [
    "### Cluster the feature descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b18bce7-f83c-4e45-960c-956c94fcf301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1613209, 128)\n"
     ]
    }
   ],
   "source": [
    "sift_data_path = 'saved/cifar10/sift_{}_{}/sift_keypoints_descriptors.pth'.format(\n",
    "    RESIZE[0], RESIZE[1])\n",
    "sift_data = torch.load(sift_data_path)\n",
    "train_descriptors = sift_data['train']['descriptors']\n",
    "flat_train_descriptors = np.concatenate(train_descriptors, axis=0)\n",
    "print(flat_train_descriptors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5738ff93-019e-4fb1-a907-c7eeecad929c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Hyperparameter search for the optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691eaa5c-bb56-4bd0-8b75-95ce8ea71bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating k-means for k=5\n",
      "Calculating k-means for k=10\n",
      "Calculating k-means for k=50\n",
      "Calculating k-means for k=75\n"
     ]
    }
   ],
   "source": [
    "ks = [5, 10, 50, 75, 100, 150]\n",
    "n_init = 10\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    print(\"Calculating k-means for k={}\".format(k))\n",
    "    kmeans = KMeans(n_clusters=k, n_init=n_init)\n",
    "    kmeans = kmeans.fit(flat_train_descriptors)\n",
    "    print(\"Inertia: {}\".format(kmeans.inertia_))\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    \n",
    "plot(\n",
    "    xs=ks,\n",
    "    ys=inertias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38934437-fbef-4374-b56f-2da5883f73af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 10, 50, 75, 100, 150] [205773570048.0, 189882646528.0, 158591074304.0, 151840161792.0, 147232325632.0, 141014695936.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 432x288 with 1 Axes>, <Axes: >)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ks, inertias)\n",
    "plot(\n",
    "    xs=ks,\n",
    "    ys=inertias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec670f-72f5-49fd-88c7-c591131cb65f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Make clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf6758d0-ae32-4f16-a7cd-5b30146f6d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating kmeans clusters with k=50\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "n_init = 10\n",
    "print(\"Calculating kmeans clusters with k={}\".format(k))\n",
    "kmeans = KMeans(n_clusters=k, n_init=n_init)\n",
    "kmeans = kmeans.fit(flat_train_descriptors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20df22c4-7660-45b3-9e64-7fb7137931d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means with k=50 saved to 'saved/cifar10/sift_128_128/50means/descriptor_kmeans.pth\n"
     ]
    }
   ],
   "source": [
    "kmeans_save_path = os.path.join(cifar10_save_dir, \n",
    "                                'sift_{}_{}'.format(RESIZE[0], RESIZE[1]),\n",
    "                                '{}means'.format(k), \n",
    "                                'descriptor_kmeans.pth')\n",
    "ensure_dir(os.path.dirname(kmeans_save_path))\n",
    "if not os.path.exists(kmeans_save_path):\n",
    "    torch.save(kmeans, kmeans_save_path)\n",
    "    print(\"K-means with k={} saved to '{}\".format(k, kmeans_save_path))\n",
    "else:\n",
    "    print(\"K-means model already saved to {}\".format(kmeans_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2dd689-8f23-4c7a-8407-4000f356c632",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### For each descriptor in training and test set, create a histogram representing the features present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfcbb626-a9d9-48a9-a0b8-2726cd586780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 50000/50000 [00:13<00:00, 3762.39it/s]\n",
      "100%|███████████████████████████████████| 10000/10000 [00:02<00:00, 3818.16it/s]\n"
     ]
    }
   ],
   "source": [
    "kmeans_path = os.path.join(cifar10_save_dir, \n",
    "                                'sift_{}_{}'.format(RESIZE[0], RESIZE[1]),\n",
    "                                '{}means'.format(k), \n",
    "                                'descriptor_kmeans.pth')\n",
    "\n",
    "kmeans = torch.load(kmeans_path)\n",
    "debug = False\n",
    "\n",
    "histogram_data = {}\n",
    "# for split, descriptors in zip(['train', 'test'], [train_descriptors, test_descriptors]):\n",
    "for split in ['train', 'test']:\n",
    "    descriptors = sift_data[split]['descriptors']\n",
    "    histogram_vectors = []\n",
    "\n",
    "    for idx, image_descriptors in enumerate(tqdm(descriptors, total=len(descriptors))):\n",
    "        if debug and idx == 5:\n",
    "            break\n",
    "        n_descriptors = len(image_descriptors)\n",
    "        descriptor_clusters = kmeans.predict(image_descriptors)\n",
    "        histogram = np.zeros(k)\n",
    "        for cluster_idx in descriptor_clusters:\n",
    "            histogram[cluster_idx] += 1 / n_descriptors  # add 1/n_descriptors bc histogram will be normalized\n",
    "\n",
    "        histogram_vectors.append(histogram)\n",
    "    histogram_vectors = np.stack(histogram_vectors, axis=0)\n",
    "    histogram_data[split] = histogram_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1ffee22-5afd-41d4-b6db-a39f8fefc40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (50000, 50) Test shape: (10000, 50)\n",
      "Saved train histogram vectors to saved/cifar10/sift_128_128/50means/histogram_vectors.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape: {} Test shape: {}\".format(histogram_data['train'].shape, histogram_data['test'].shape))\n",
    "histogram_vectors_save_path = os.path.join(os.path.dirname(kmeans_path), 'histogram_vectors.pth')\n",
    "if not os.path.exists(histogram_vectors_save_path):\n",
    "    torch.save(histogram_data, histogram_vectors_save_path)\n",
    "    print(\"Saved train histogram vectors to {}\".format(histogram_vectors_save_path))\n",
    "else:\n",
    "    print(\"Histogram vectors already exists at {}\".format(histogram_vectors_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89896e53-a94c-487a-a015-175d6ef32096",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get CIFAR10 model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "06b09bf8-996e-451b-8504-650e2d7b0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'src')\n",
    "from model.base_model import BaseModel\n",
    "sys.path.insert(0, os.path.join('external_code', 'PyTorch_CIFAR10'))\n",
    "# from cifar10_models.densenet import densenet121, densenet161, densenet169\n",
    "# from cifar10_models.googlenet import googlenet\n",
    "# from cifar10_models.inception import inception_v3\n",
    "# from cifar10_models.mobilenetv2 import mobilenet_v2\n",
    "from cifar10_models.resnet import resnet18, resnet34, resnet50\n",
    "\n",
    "class CIFAR10PretrainedModel(BaseModel):\n",
    "    '''\n",
    "    Simple model wrapper for models in external_code/PyTorch_CIFAR10/cifar10_models/state_dicts\n",
    "\n",
    "    Arg(s):\n",
    "        type : str\n",
    "            Name of architecture, must be key in self.all_classifiers\n",
    "\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 type,\n",
    "                 checkpoint_path=\"\",\n",
    "                 device=None):\n",
    "        super().__init__()\n",
    "        self.all_classifiers = {\n",
    "            # \"vgg11_bn\": vgg11_bn(),\n",
    "            # \"vgg13_bn\": vgg13_bn(),\n",
    "            # \"vgg16_bn\": vgg16_bn(),\n",
    "            # \"vgg19_bn\": vgg19_bn(),\n",
    "            \"resnet18\": resnet18(),\n",
    "            \"resnet34\": resnet34(),\n",
    "            \"resnet50\": resnet50(),\n",
    "            # \"densenet121\": densenet121(),\n",
    "            # \"densenet161\": densenet161(),\n",
    "            # \"densenet169\": densenet169(),\n",
    "            # \"mobilenet_v2\": mobilenet_v2(),\n",
    "            # \"googlenet\": googlenet(),\n",
    "            # \"inception_v3\": inception_v3()\n",
    "        }\n",
    "        if type not in self.all_classifiers:\n",
    "            raise ValueError(\"Architecture {} not available for pretrained CIFAR-10 models\".format(type))\n",
    "        self.model = self.all_classifiers[type]\n",
    "        # self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "        # Restore weights if checkpoint_path is valid\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "\n",
    "        if self.checkpoint_path != \"\":\n",
    "            try:\n",
    "                self.restore_model(checkpoint_path)\n",
    "            except:\n",
    "                checkpoint = torch.load(checkpoint_path)\n",
    "                self.model.load_state_dict(checkpoint)\n",
    "\n",
    "        # Store parameters\n",
    "        self.model_parameters = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "        self.n_params = sum([np.prod(p.size()) for p in self.model_parameters])\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.logits = self.model(x)\n",
    "        return self.logits\n",
    "\n",
    "    def get_features(self, x):\n",
    "        features = self.model.features(x)\n",
    "        return features\n",
    "\n",
    "    def get_checkpoint_path(self):\n",
    "        return self.checkpoint_path\n",
    "\n",
    "    def get_n_params(self):\n",
    "        return self.n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e64793ca-8497-4cf6-b724-2a98850b4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and load data loaders\n",
    "cifar10_resnet18 = CIFAR10PretrainedModel(\n",
    "    type='resnet18',\n",
    "    checkpoint_path='/n/fs/ac-alignment/explain-alignment/checkpoints/cifar10_state_dicts/resnet18.pt')\n",
    "\n",
    "cifar10_train_dataset = CIFAR10TorchDataset(\n",
    "    cifar_dir=processed_cifar_dir,\n",
    "    split='train')\n",
    "cifar10_train_dataloader = torch.utils.data.DataLoader(\n",
    "    cifar10_train_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=256,\n",
    "    num_workers=8)\n",
    "\n",
    "cifar10_test_dataset = CIFAR10TorchDataset(\n",
    "    cifar_dir=processed_cifar_dir,\n",
    "    split='test')\n",
    "cifar10_test_dataloader = torch.utils.data.DataLoader(\n",
    "    cifar10_test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=256,\n",
    "    num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c6c9a346-dfa2-439b-ae1b-fb9628cf410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 196/196 [00:03<00:00, 60.34it/s]\n",
      "100%|███████████████████████████████████████████| 40/40 [00:01<00:00, 32.20it/s]\n"
     ]
    }
   ],
   "source": [
    "device, _ = prepare_device(n_gpu_use=1)\n",
    "cifar10_resnet18 = cifar10_resnet18.to(device)\n",
    "metric_fns = [getattr(module_metric, 'accuracy')]\n",
    "\n",
    "\n",
    "train_predict_log = predict(\n",
    "    data_loader=cifar10_train_dataloader,\n",
    "    model=cifar10_resnet18,\n",
    "    metric_fns=metric_fns,\n",
    "    device=device)\n",
    "\n",
    "test_predict_log = predict(\n",
    "    data_loader=cifar10_test_dataloader,\n",
    "    model=cifar10_resnet18,\n",
    "    metric_fns=metric_fns,\n",
    "    device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fd75fa57-8594-420e-92ed-d0005a58e3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train/test outputs to saved/cifar10/resnet18/outputs_predictions.pth\n"
     ]
    }
   ],
   "source": [
    "# Save outputs\n",
    "save_path = os.path.join('saved', 'cifar10', 'resnet18', 'outputs_predictions.pth')\n",
    "ensure_dir(os.path.dirname(save_path_template))\n",
    "save_data = {}\n",
    "for split, logs in zip(['train', 'test'], [train_predict_log, test_predict_log]):\n",
    "    outputs = logs['logits']\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    \n",
    "    outputs = outputs.cpu().numpy()\n",
    "    probabilities = probabilities.cpu().numpy()\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    \n",
    "    split_data = {\n",
    "        'outputs': outputs,\n",
    "        'probabilities': probabilities,\n",
    "        'predictions': predictions,\n",
    "        'accuracy': logs['metrics']['accuracy']\n",
    "    }\n",
    "    save_data[split] = split_data\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    torch.save(save_data, save_path)\n",
    "    print(\"Saved train/test outputs to {}\".format(save_path))\n",
    "else:\n",
    "    print(\"Train/test results already saved to {}\".format(save_path)) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c194ce7-ca38-469c-9654-24a012c71ec1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Train linear layer to predict model's soft label outputs from histogram features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6495b048-3fc9-4cf1-bff0-276cfa0d2a86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Hyperparam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaad6186-44d5-47d6-8e3d-4886480a9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path = 'configs/train_cifar10_sift_explainer.json'\n",
    "# debug = False\n",
    "# if debug:\n",
    "#     learning_rates = [1e-6] #, 1e-5, 1e-4, 1e-3, 5e-2, 1e-2, 5e-1, 1e-1]\n",
    "#     weight_decays = [0, 1e-1] #, 1e-2, 1e-3]\n",
    "# else:\n",
    "#     learning_rates = [1e-6, 1e-5, 1e-4, 1e-3, 5e-2, 1e-2, 5e-1, 1e-1]\n",
    "#     weight_decays = [0, 1e-1, 1e-2, 1e-3]\n",
    "\n",
    "# config_json = read_json(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97a2b86-ba1e-4274-bc7f-5f813d2e3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_args = config_json['dataset']['args']\n",
    "# train_descriptors_dataset = module_data.KDDataset(split='train', **dataset_args)\n",
    "# test_descriptors_dataset = module_data.KDDataset(split='test', **dataset_args)\n",
    "\n",
    "# dataloader_args = config_json['data_loader']['args']\n",
    "# train_descriptors_dataloader = torch.utils.data.DataLoader(\n",
    "#     train_descriptors_dataset,\n",
    "#     shuffle=True,\n",
    "#     **dataloader_args)\n",
    "# test_descriptors_dataloader = torch.utils.data.DataLoader(\n",
    "#     test_descriptors_dataset,\n",
    "#     shuffle=False,\n",
    "#     **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28342405-1fa0-4d35-bb22-73b4ea11c35c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter search\n",
      "Learning rates: [1e-06, 1e-05, 0.0001, 0.001, 0.05, 0.01, 0.5, 0.1]\n",
      "Weight decays: [0, 0.1, 0.01, 0.001]\n",
      "[0525_102954] Trial 1/32: LR = 1e-06 WD = 0\n",
      "OrderedDict([('lr', 1e-06), ('weight_decay', 0), ('amsgrad', False)])\n",
      "Created LinearLayers model with 760 trainable parameters\n",
      "Training from scratch.\n",
      "Checkpoint save directory: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models\n",
      "Train Epoch: 1 [0/196 (0%)] Loss: 2.308654\n",
      "Train Epoch: 1 [48/196 (24%)] Loss: 2.301465\n",
      "Train Epoch: 1 [96/196 (49%)] Loss: 2.310005\n",
      "Train Epoch: 1 [144/196 (73%)] Loss: 2.310523\n",
      "Train Epoch: 1 [192/196 (98%)] Loss: 2.302329\n",
      "    epoch          : 1\n",
      "    val_TP         : [  0   0 155 473   0   3   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7295 4802 8988 8976 9019 5996 8982 8994]\n",
      "    val_FPs        : [   0    0 1703 4206    5   22    0 3018    0    0]\n",
      "    val_FNs        : [1016  990  847  519 1007  999  981  571 1018 1006]\n",
      "    val_accuracy   : 0.1046\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.745  0.5275 0.8988 0.8979 0.9019 0.6411 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8209199999999999\n",
      "    val_precision  : [0.         0.         0.08342304 0.10108998 0.         0.12\n",
      " 0.         0.12088552 0.         0.        ]\n",
      "    val_precision_mean: 0.04253985348790675\n",
      "    val_recall     : [0.         0.         0.15469062 0.47681452 0.         0.00299401\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10553916417965614\n",
      "    val_predicted_class_distribution: [   0    0 1858 4679    5   25    0 3433    0    0]\n",
      "    val_f1         : [0.         0.         0.10839161 0.16681361 0.         0.00584226\n",
      " 0.         0.1878253  0.         0.        ]\n",
      "    val_f1_mean    : 0.046887278035939686\n",
      "    val_loss       : 2.286001682281494\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/196 (0%)] Loss: 2.304604\n",
      "Train Epoch: 2 [48/196 (24%)] Loss: 2.306756\n",
      "Train Epoch: 2 [96/196 (49%)] Loss: 2.298509\n",
      "Train Epoch: 2 [144/196 (73%)] Loss: 2.298776\n",
      "Train Epoch: 2 [192/196 (98%)] Loss: 2.316076\n",
      "    epoch          : 2\n",
      "    val_TP         : [  0   0 155 473   0   3   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7296 4801 8988 8975 9019 5997 8982 8994]\n",
      "    val_FPs        : [   0    0 1702 4207    5   23    0 3017    0    0]\n",
      "    val_FNs        : [1016  990  847  519 1007  999  981  571 1018 1006]\n",
      "    val_accuracy   : 0.1046\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7451 0.5274 0.8988 0.8978 0.9019 0.6412 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8209199999999999\n",
      "    val_precision  : [0.         0.         0.08346796 0.10106838 0.         0.11538462\n",
      " 0.         0.12092075 0.         0.        ]\n",
      "    val_precision_mean: 0.04208416964475123\n",
      "    val_recall     : [0.         0.         0.15469062 0.47681452 0.         0.00299401\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10553916417965614\n",
      "    val_predicted_class_distribution: [   0    0 1857 4680    5   26    0 3432    0    0]\n",
      "    val_f1         : [0.         0.         0.10842952 0.1667842  0.         0.00583658\n",
      " 0.         0.18786781 0.         0.        ]\n",
      "    val_f1_mean    : 0.04689181132801879\n",
      "    val_loss       : 2.2859935760498047\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [0/196 (0%)] Loss: 2.299911\n",
      "Train Epoch: 3 [48/196 (24%)] Loss: 2.309268\n",
      "Train Epoch: 3 [96/196 (49%)] Loss: 2.301476\n",
      "Train Epoch: 3 [144/196 (73%)] Loss: 2.306011\n",
      "Train Epoch: 3 [192/196 (98%)] Loss: 2.303592\n",
      "    epoch          : 3\n",
      "    val_TP         : [  0   0 155 475   0   3   0 414   0   0]\n",
      "    val_TN         : [8984 9010 7299 4800 8988 8973 9019 5998 8982 8994]\n",
      "    val_FPs        : [   0    0 1699 4208    5   25    0 3016    0    0]\n",
      "    val_FNs        : [1016  990  847  517 1007  999  981  572 1018 1006]\n",
      "    val_accuracy   : 0.1047\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7454 0.5275 0.8988 0.8976 0.9019 0.6412 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8209399999999999\n",
      "    val_precision  : [0.         0.         0.08360302 0.10143071 0.         0.10714286\n",
      " 0.         0.12069971 0.         0.        ]\n",
      "    val_precision_mean: 0.04128762929057648\n",
      "    val_recall     : [0.         0.         0.15469062 0.47883065 0.         0.00299401\n",
      " 0.         0.4198783  0.         0.        ]\n",
      "    val_recall_mean: 0.1056393572045858\n",
      "    val_predicted_class_distribution: [   0    0 1854 4683    5   28    0 3430    0    0]\n",
      "    val_f1         : [0.         0.         0.10854342 0.16740088 0.         0.00582524\n",
      " 0.         0.1875     0.         0.        ]\n",
      "    val_f1_mean    : 0.046926954114266214\n",
      "    val_loss       : 2.2859878540039062\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [0/196 (0%)] Loss: 2.295830\n",
      "Train Epoch: 4 [48/196 (24%)] Loss: 2.308899\n",
      "Train Epoch: 4 [96/196 (49%)] Loss: 2.302775\n",
      "Train Epoch: 4 [144/196 (73%)] Loss: 2.301301\n",
      "Train Epoch: 4 [192/196 (98%)] Loss: 2.303488\n",
      "    epoch          : 4\n",
      "    val_TP         : [  0   0 156 475   0   3   0 414   0   0]\n",
      "    val_TN         : [8984 9010 7301 4799 8988 8973 9019 5998 8982 8994]\n",
      "    val_FPs        : [   0    0 1697 4209    5   25    0 3016    0    0]\n",
      "    val_FNs        : [1016  990  846  517 1007  999  981  572 1018 1006]\n",
      "    val_accuracy   : 0.1048\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7457 0.5274 0.8988 0.8976 0.9019 0.6412 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.82096\n",
      "    val_precision  : [0.         0.         0.0841878  0.10140905 0.         0.10714286\n",
      " 0.         0.12069971 0.         0.        ]\n",
      "    val_precision_mean: 0.04134394212516882\n",
      "    val_recall     : [0.         0.         0.15568862 0.47883065 0.         0.00299401\n",
      " 0.         0.4198783  0.         0.        ]\n",
      "    val_recall_mean: 0.10573915760378738\n",
      "    val_predicted_class_distribution: [   0    0 1853 4684    5   28    0 3430    0    0]\n",
      "    val_f1         : [0.         0.         0.10928196 0.16737139 0.         0.00582524\n",
      " 0.         0.1875     0.         0.        ]\n",
      "    val_f1_mean    : 0.04699785924911708\n",
      "    val_loss       : 2.285982131958008\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/196 (0%)] Loss: 2.304317\n",
      "Train Epoch: 5 [48/196 (24%)] Loss: 2.311249\n",
      "Train Epoch: 5 [96/196 (49%)] Loss: 2.303680\n",
      "Train Epoch: 5 [144/196 (73%)] Loss: 2.299185\n",
      "Train Epoch: 5 [192/196 (98%)] Loss: 2.301899\n",
      "    epoch          : 5\n",
      "    val_TP         : [  0   0 157 475   0   3   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7302 4801 8988 8973 9019 5997 8982 8994]\n",
      "    val_FPs        : [   0    0 1696 4207    5   25    0 3017    0    0]\n",
      "    val_FNs        : [1016  990  845  517 1007  999  981  571 1018 1006]\n",
      "    val_accuracy   : 0.105\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7459 0.5276 0.8988 0.8976 0.9019 0.6412 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8210000000000001\n",
      "    val_precision  : [0.         0.         0.08472747 0.10145237 0.         0.10714286\n",
      " 0.         0.12092075 0.         0.        ]\n",
      "    val_precision_mean: 0.04142434428145594\n",
      "    val_recall     : [0.         0.         0.15668663 0.47883065 0.         0.00299401\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10594037788128512\n",
      "    val_predicted_class_distribution: [   0    0 1853 4682    5   28    0 3432    0    0]\n",
      "    val_f1         : [0.         0.         0.10998249 0.16743038 0.         0.00582524\n",
      " 0.         0.18786781 0.         0.        ]\n",
      "    val_f1_mean    : 0.04711059272825337\n",
      "    val_loss       : 2.285975933074951\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [0/196 (0%)] Loss: 2.298853\n",
      "Train Epoch: 6 [48/196 (24%)] Loss: 2.314916\n",
      "Train Epoch: 6 [96/196 (49%)] Loss: 2.305901\n",
      "Train Epoch: 6 [144/196 (73%)] Loss: 2.306633\n",
      "Train Epoch: 6 [192/196 (98%)] Loss: 2.306074\n",
      "    epoch          : 6\n",
      "    val_TP         : [  0   0 157 475   0   3   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7300 4805 8988 8973 9019 5995 8982 8994]\n",
      "    val_FPs        : [   0    0 1698 4203    5   25    0 3019    0    0]\n",
      "    val_FNs        : [1016  990  845  517 1007  999  981  571 1018 1006]\n",
      "    val_accuracy   : 0.105\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7457 0.528  0.8988 0.8976 0.9019 0.641  0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8210000000000001\n",
      "    val_precision  : [0.         0.         0.08463612 0.10153912 0.         0.10714286\n",
      " 0.         0.12085032 0.         0.        ]\n",
      "    val_precision_mean: 0.04141684153491344\n",
      "    val_recall     : [0.         0.         0.15668663 0.47883065 0.         0.00299401\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10594037788128512\n",
      "    val_predicted_class_distribution: [   0    0 1855 4678    5   28    0 3434    0    0]\n",
      "    val_f1         : [0.         0.         0.1099055  0.1675485  0.         0.00582524\n",
      " 0.         0.18778281 0.         0.        ]\n",
      "    val_f1_mean    : 0.047106204430490885\n",
      "    val_loss       : 2.285970687866211\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [0/196 (0%)] Loss: 2.315527\n",
      "Train Epoch: 7 [48/196 (24%)] Loss: 2.300157\n",
      "Train Epoch: 7 [96/196 (49%)] Loss: 2.307732\n",
      "Train Epoch: 7 [144/196 (73%)] Loss: 2.299602\n",
      "Train Epoch: 7 [192/196 (98%)] Loss: 2.307986\n",
      "    epoch          : 7\n",
      "    val_TP         : [  0   0 157 474   0   3   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7298 4806 8988 8973 9019 5995 8982 8994]\n",
      "    val_FPs        : [   0    0 1700 4202    5   25    0 3019    0    0]\n",
      "    val_FNs        : [1016  990  845  518 1007  999  981  571 1018 1006]\n",
      "    val_accuracy   : 0.1049\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7455 0.528  0.8988 0.8976 0.9019 0.641  0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8209799999999999\n",
      "    val_precision  : [0.         0.         0.08454496 0.10136869 0.         0.10714286\n",
      " 0.         0.12085032 0.         0.        ]\n",
      "    val_precision_mean: 0.041390683365536536\n",
      "    val_recall     : [0.         0.         0.15668663 0.47782258 0.         0.00299401\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10583957142967222\n",
      "    val_predicted_class_distribution: [   0    0 1857 4676    5   28    0 3434    0    0]\n",
      "    val_f1         : [0.         0.         0.10982861 0.16725476 0.         0.00582524\n",
      " 0.         0.18778281 0.         0.        ]\n",
      "    val_f1_mean    : 0.047069142313593805\n",
      "    val_loss       : 2.2859649658203125\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [0/196 (0%)] Loss: 2.306714\n",
      "Train Epoch: 8 [48/196 (24%)] Loss: 2.303858\n",
      "Train Epoch: 8 [96/196 (49%)] Loss: 2.299958\n",
      "Train Epoch: 8 [144/196 (73%)] Loss: 2.306361\n",
      "Train Epoch: 8 [192/196 (98%)] Loss: 2.298908\n",
      "    epoch          : 8\n",
      "    val_TP         : [  0   0 157 474   0   2   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7295 4808 8988 8973 9019 5995 8982 8994]\n",
      "    val_FPs        : [   0    0 1703 4200    5   25    0 3019    0    0]\n",
      "    val_FNs        : [1016  990  845  518 1007 1000  981  571 1018 1006]\n",
      "    val_accuracy   : 0.1048\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7452 0.5282 0.8988 0.8975 0.9019 0.641  0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.82096\n",
      "    val_precision  : [0.         0.         0.0844086  0.10141207 0.         0.07407407\n",
      " 0.         0.12085032 0.         0.        ]\n",
      "    val_precision_mean: 0.038074506330300836\n",
      "    val_recall     : [0.         0.         0.15668663 0.47782258 0.         0.00199601\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10573977103047064\n",
      "    val_predicted_class_distribution: [   0    0 1860 4674    5   27    0 3434    0    0]\n",
      "    val_f1         : [0.         0.         0.10971349 0.1673138  0.         0.00388727\n",
      " 0.         0.18778281 0.         0.        ]\n",
      "    val_f1_mean    : 0.046869736331895395\n",
      "    val_loss       : 2.285959243774414\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/196 (0%)] Loss: 2.297857\n",
      "Train Epoch: 9 [48/196 (24%)] Loss: 2.301640\n",
      "Train Epoch: 9 [96/196 (49%)] Loss: 2.310166\n",
      "Train Epoch: 9 [144/196 (73%)] Loss: 2.308038\n",
      "Train Epoch: 9 [192/196 (98%)] Loss: 2.299278\n",
      "    epoch          : 9\n",
      "    val_TP         : [  0   0 158 475   0   2   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7295 4808 8988 8972 9019 5998 8982 8994]\n",
      "    val_FPs        : [   0    0 1703 4200    5   26    0 3016    0    0]\n",
      "    val_FNs        : [1016  990  844  517 1007 1000  981  571 1018 1006]\n",
      "    val_accuracy   : 0.105\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7453 0.5283 0.8988 0.8974 0.9019 0.6413 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8210000000000001\n",
      "    val_precision  : [0.         0.         0.08490059 0.10160428 0.         0.07142857\n",
      " 0.         0.12095599 0.         0.        ]\n",
      "    val_precision_mean: 0.03788894300909344\n",
      "    val_recall     : [0.         0.         0.15768463 0.47883065 0.         0.00199601\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10594037788128512\n",
      "    val_predicted_class_distribution: [   0    0 1861 4675    5   28    0 3431    0    0]\n",
      "    val_f1         : [0.         0.         0.11037373 0.1676372  0.         0.0038835\n",
      " 0.         0.18791035 0.         0.        ]\n",
      "    val_f1_mean    : 0.04698047731920928\n",
      "    val_loss       : 2.285954475402832\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [0/196 (0%)] Loss: 2.307041\n",
      "Train Epoch: 10 [48/196 (24%)] Loss: 2.305289\n",
      "Train Epoch: 10 [96/196 (49%)] Loss: 2.304673\n",
      "Train Epoch: 10 [144/196 (73%)] Loss: 2.297333\n",
      "Train Epoch: 10 [192/196 (98%)] Loss: 2.307833\n",
      "    epoch          : 10\n",
      "    val_TP         : [  0   0 158 474   0   2   0 416   0   0]\n",
      "    val_TN         : [8984 9010 7294 4811 8988 8972 9019 5996 8982 8994]\n",
      "    val_FPs        : [   0    0 1704 4197    5   26    0 3018    0    0]\n",
      "    val_FNs        : [1016  990  844  518 1007 1000  981  570 1018 1006]\n",
      "    val_accuracy   : 0.105\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7452 0.5285 0.8988 0.8974 0.9019 0.6412 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8210000000000001\n",
      "    val_precision  : [0.         0.         0.08485499 0.1014772  0.         0.07142857\n",
      " 0.         0.12114153 0.         0.        ]\n",
      "    val_precision_mean: 0.03789022917183955\n",
      "    val_recall     : [0.         0.         0.15768463 0.47782258 0.         0.00199601\n",
      " 0.         0.42190669 0.         0.        ]\n",
      "    val_recall_mean: 0.10594099130796837\n",
      "    val_predicted_class_distribution: [   0    0 1862 4671    5   28    0 3434    0    0]\n",
      "    val_f1         : [0.         0.         0.1103352  0.16740244 0.         0.0038835\n",
      " 0.         0.18823529 0.         0.        ]\n",
      "    val_f1_mean    : 0.046985642166492085\n",
      "    val_loss       : 2.28594708442688\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [0/196 (0%)] Loss: 2.305669\n",
      "Train Epoch: 11 [48/196 (24%)] Loss: 2.306994\n",
      "Train Epoch: 11 [96/196 (49%)] Loss: 2.302781\n",
      "Train Epoch: 11 [144/196 (73%)] Loss: 2.305951\n",
      "Train Epoch: 11 [192/196 (98%)] Loss: 2.304638\n",
      "    epoch          : 11\n",
      "    val_TP         : [  0   0 158 474   0   2   0 416   0   0]\n",
      "    val_TN         : [8984 9010 7294 4810 8988 8972 9019 5997 8982 8994]\n",
      "    val_FPs        : [   0    0 1704 4198    5   26    0 3017    0    0]\n",
      "    val_FNs        : [1016  990  844  518 1007 1000  981  570 1018 1006]\n",
      "    val_accuracy   : 0.105\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7452 0.5284 0.8988 0.8974 0.9019 0.6413 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8210000000000001\n",
      "    val_precision  : [0.         0.         0.08485499 0.10145548 0.         0.07142857\n",
      " 0.         0.12117681 0.         0.        ]\n",
      "    val_precision_mean: 0.03789158587928999\n",
      "    val_recall     : [0.         0.         0.15768463 0.47782258 0.         0.00199601\n",
      " 0.         0.42190669 0.         0.        ]\n",
      "    val_recall_mean: 0.10594099130796837\n",
      "    val_predicted_class_distribution: [   0    0 1862 4672    5   28    0 3433    0    0]\n",
      "    val_f1         : [0.         0.         0.1103352  0.16737288 0.         0.0038835\n",
      " 0.         0.18827789 0.         0.        ]\n",
      "    val_f1_mean    : 0.04698694629578383\n",
      "    val_loss       : 2.285939931869507\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [0/196 (0%)] Loss: 2.304575\n",
      "Train Epoch: 12 [48/196 (24%)] Loss: 2.302416\n",
      "Train Epoch: 12 [96/196 (49%)] Loss: 2.302908\n",
      "Train Epoch: 12 [144/196 (73%)] Loss: 2.302905\n",
      "Train Epoch: 12 [192/196 (98%)] Loss: 2.302837\n",
      "    epoch          : 12\n",
      "    val_TP         : [  0   0 158 474   0   2   0 416   0   0]\n",
      "    val_TN         : [8984 9010 7295 4812 8988 8972 9019 5994 8982 8994]\n",
      "    val_FPs        : [   0    0 1703 4196    5   26    0 3020    0    0]\n",
      "    val_FNs        : [1016  990  844  518 1007 1000  981  570 1018 1006]\n",
      "    val_accuracy   : 0.105\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7453 0.5286 0.8988 0.8974 0.9019 0.641  0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8210000000000001\n",
      "    val_precision  : [0.         0.         0.08490059 0.10149893 0.         0.07142857\n",
      " 0.         0.12107101 0.         0.        ]\n",
      "    val_precision_mean: 0.03788991046504122\n",
      "    val_recall     : [0.         0.         0.15768463 0.47782258 0.         0.00199601\n",
      " 0.         0.42190669 0.         0.        ]\n",
      "    val_recall_mean: 0.10594099130796837\n",
      "    val_predicted_class_distribution: [   0    0 1861 4670    5   28    0 3436    0    0]\n",
      "    val_f1         : [0.         0.         0.11037373 0.167432   0.         0.0038835\n",
      " 0.         0.18815016 0.         0.        ]\n",
      "    val_f1_mean    : 0.04698393901165162\n",
      "    val_loss       : 2.2859349250793457\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [0/196 (0%)] Loss: 2.308403\n",
      "Train Epoch: 13 [48/196 (24%)] Loss: 2.299905\n",
      "Train Epoch: 13 [96/196 (49%)] Loss: 2.309937\n",
      "Train Epoch: 13 [144/196 (73%)] Loss: 2.306554\n",
      "Train Epoch: 13 [192/196 (98%)] Loss: 2.306227\n",
      "    epoch          : 13\n",
      "    val_TP         : [  0   0 158 474   0   2   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7292 4814 8988 8971 9019 5995 8982 8994]\n",
      "    val_FPs        : [   0    0 1706 4194    5   27    0 3019    0    0]\n",
      "    val_FNs        : [1016  990  844  518 1007 1000  981  571 1018 1006]\n",
      "    val_accuracy   : 0.1049\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.745  0.5288 0.8988 0.8973 0.9019 0.641  0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8209800000000002\n",
      "    val_precision  : [0.         0.         0.08476395 0.10154242 0.         0.06896552\n",
      " 0.         0.12085032 0.         0.        ]\n",
      "    val_precision_mean: 0.03761222025178258\n",
      "    val_recall     : [0.         0.         0.15768463 0.47782258 0.         0.00199601\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10583957142967222\n",
      "    val_predicted_class_distribution: [   0    0 1864 4668    5   29    0 3434    0    0]\n",
      "    val_f1         : [0.         0.         0.1102582  0.16749117 0.         0.00387973\n",
      " 0.         0.18778281 0.         0.        ]\n",
      "    val_f1_mean    : 0.04694118995079115\n",
      "    val_loss       : 2.2859277725219727\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [0/196 (0%)] Loss: 2.298985\n",
      "Train Epoch: 14 [48/196 (24%)] Loss: 2.306030\n",
      "Train Epoch: 14 [96/196 (49%)] Loss: 2.308930\n",
      "Train Epoch: 14 [144/196 (73%)] Loss: 2.308980\n",
      "Train Epoch: 14 [192/196 (98%)] Loss: 2.308788\n",
      "    epoch          : 14\n",
      "    val_TP         : [  0   0 158 474   0   2   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7291 4816 8988 8971 9019 5994 8982 8994]\n",
      "    val_FPs        : [   0    0 1707 4192    5   27    0 3020    0    0]\n",
      "    val_FNs        : [1016  990  844  518 1007 1000  981  571 1018 1006]\n",
      "    val_accuracy   : 0.1049\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7449 0.529  0.8988 0.8973 0.9019 0.6409 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8209800000000002\n",
      "    val_precision  : [0.         0.         0.0847185  0.10158594 0.         0.06896552\n",
      " 0.         0.12081514 0.         0.        ]\n",
      "    val_precision_mean: 0.03760850950319766\n",
      "    val_recall     : [0.         0.         0.15768463 0.47782258 0.         0.00199601\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10583957142967222\n",
      "    val_predicted_class_distribution: [   0    0 1865 4666    5   29    0 3435    0    0]\n",
      "    val_f1         : [0.         0.         0.11021974 0.16755037 0.         0.00387973\n",
      " 0.         0.18774033 0.         0.        ]\n",
      "    val_f1_mean    : 0.046939017170740074\n",
      "    val_loss       : 2.2859225273132324\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [0/196 (0%)] Loss: 2.301963\n",
      "Train Epoch: 15 [48/196 (24%)] Loss: 2.305826\n",
      "Train Epoch: 15 [96/196 (49%)] Loss: 2.305232\n",
      "Train Epoch: 15 [144/196 (73%)] Loss: 2.299156\n",
      "Train Epoch: 15 [192/196 (98%)] Loss: 2.305772\n",
      "    epoch          : 15\n",
      "    val_TP         : [  0   0 159 474   0   2   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7289 4817 8987 8971 9019 5997 8982 8994]\n",
      "    val_FPs        : [   0    0 1709 4191    6   27    0 3017    0    0]\n",
      "    val_FNs        : [1016  990  843  518 1007 1000  981  571 1018 1006]\n",
      "    val_accuracy   : 0.105\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7448 0.5291 0.8987 0.8973 0.9019 0.6412 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8210000000000001\n",
      "    val_precision  : [0.         0.         0.08511777 0.10160772 0.         0.06896552\n",
      " 0.         0.12092075 0.         0.        ]\n",
      "    val_precision_mean: 0.03766117532231979\n",
      "    val_recall     : [0.         0.         0.15868263 0.47782258 0.         0.00199601\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10593937182887384\n",
      "    val_predicted_class_distribution: [   0    0 1868 4665    6   29    0 3432    0    0]\n",
      "    val_f1         : [0.         0.         0.11080139 0.16757999 0.         0.00387973\n",
      " 0.         0.18786781 0.         0.        ]\n",
      "    val_f1_mean    : 0.04701289250311723\n",
      "    val_loss       : 2.285916328430176\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [0/196 (0%)] Loss: 2.299519\n",
      "Train Epoch: 16 [48/196 (24%)] Loss: 2.299720\n",
      "Train Epoch: 16 [96/196 (49%)] Loss: 2.302661\n",
      "Train Epoch: 16 [144/196 (73%)] Loss: 2.303665\n",
      "Train Epoch: 16 [192/196 (98%)] Loss: 2.308808\n",
      "    epoch          : 16\n",
      "    val_TP         : [  0   0 160 474   0   2   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7289 4816 8987 8971 9019 5999 8982 8994]\n",
      "    val_FPs        : [   0    0 1709 4192    6   27    0 3015    0    0]\n",
      "    val_FNs        : [1016  990  842  518 1007 1000  981  571 1018 1006]\n",
      "    val_accuracy   : 0.1051\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7449 0.529  0.8987 0.8973 0.9019 0.6414 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8210200000000001\n",
      "    val_precision  : [0.         0.         0.08560728 0.10158594 0.         0.06896552\n",
      " 0.         0.12099125 0.         0.        ]\n",
      "    val_precision_mean: 0.03771499883528994\n",
      "    val_recall     : [0.         0.         0.15968064 0.47782258 0.         0.00199601\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10603917222807542\n",
      "    val_predicted_class_distribution: [   0    0 1869 4666    6   29    0 3430    0    0]\n",
      "    val_f1         : [0.         0.         0.11145942 0.16755037 0.         0.00387973\n",
      " 0.         0.1879529  0.         0.        ]\n",
      "    val_f1_mean    : 0.04708424199298701\n",
      "    val_loss       : 2.2859115600585938\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [0/196 (0%)] Loss: 2.312346\n",
      "Train Epoch: 17 [48/196 (24%)] Loss: 2.311122\n",
      "Train Epoch: 17 [96/196 (49%)] Loss: 2.298477\n",
      "Train Epoch: 17 [144/196 (73%)] Loss: 2.308170\n",
      "Train Epoch: 17 [192/196 (98%)] Loss: 2.304476\n",
      "    epoch          : 17\n",
      "    val_TP         : [  0   0 162 474   0   3   0 415   0   0]\n",
      "    val_TN         : [8984 9010 7287 4813 8987 8971 9019 6007 8982 8994]\n",
      "    val_FPs        : [   0    0 1711 4195    6   27    0 3007    0    0]\n",
      "    val_FNs        : [1016  990  840  518 1007  999  981  571 1018 1006]\n",
      "    val_accuracy   : 0.1054\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7449 0.5287 0.8987 0.8974 0.9019 0.6422 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8210799999999999\n",
      "    val_precision  : [0.         0.         0.08649226 0.10152067 0.         0.1\n",
      " 0.         0.12127411 0.         0.        ]\n",
      "    val_precision_mean: 0.04092870353546372\n",
      "    val_recall     : [0.         0.         0.16167665 0.47782258 0.         0.00299401\n",
      " 0.         0.42089249 0.         0.        ]\n",
      "    val_recall_mean: 0.10633857342568023\n",
      "    val_predicted_class_distribution: [   0    0 1873 4669    6   30    0 3422    0    0]\n",
      "    val_f1         : [0.         0.         0.11269565 0.16746158 0.         0.00581395\n",
      " 0.         0.18829401 0.         0.        ]\n",
      "    val_f1_mean    : 0.04742651957778625\n",
      "    val_loss       : 2.2859046459198\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [0/196 (0%)] Loss: 2.301010\n",
      "Train Epoch: 18 [48/196 (24%)] Loss: 2.309848\n",
      "Train Epoch: 18 [96/196 (49%)] Loss: 2.310168\n",
      "Train Epoch: 18 [144/196 (73%)] Loss: 2.310430\n",
      "Train Epoch: 18 [192/196 (98%)] Loss: 2.302141\n",
      "    epoch          : 18\n",
      "    val_TP         : [  0   0 162 474   0   3   0 416   0   0]\n",
      "    val_TN         : [8984 9010 7281 4817 8987 8971 9019 6010 8982 8994]\n",
      "    val_FPs        : [   0    0 1717 4191    6   27    0 3004    0    0]\n",
      "    val_FNs        : [1016  990  840  518 1007  999  981  570 1018 1006]\n",
      "    val_accuracy   : 0.1055\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7443 0.5291 0.8987 0.8974 0.9019 0.6426 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8211\n",
      "    val_precision  : [0.         0.         0.08621607 0.10160772 0.         0.1\n",
      " 0.         0.12163743 0.         0.        ]\n",
      "    val_precision_mean: 0.04094612163213104\n",
      "    val_recall     : [0.         0.         0.16167665 0.47782258 0.         0.00299401\n",
      " 0.         0.42190669 0.         0.        ]\n",
      "    val_recall_mean: 0.10643999330397635\n",
      "    val_predicted_class_distribution: [   0    0 1879 4665    6   30    0 3420    0    0]\n",
      "    val_f1         : [0.         0.         0.11246095 0.16757999 0.         0.00581395\n",
      " 0.         0.18883341 0.         0.        ]\n",
      "    val_f1_mean    : 0.04746883029284479\n",
      "    val_loss       : 2.2858991622924805\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [0/196 (0%)] Loss: 2.300272\n",
      "Train Epoch: 19 [48/196 (24%)] Loss: 2.304485\n",
      "Train Epoch: 19 [96/196 (49%)] Loss: 2.309172\n",
      "Train Epoch: 19 [144/196 (73%)] Loss: 2.306329\n",
      "Train Epoch: 19 [192/196 (98%)] Loss: 2.306779\n",
      "    epoch          : 19\n",
      "    val_TP         : [  0   0 163 474   0   3   0 416   0   0]\n",
      "    val_TN         : [8984 9010 7281 4818 8987 8971 9019 6010 8982 8994]\n",
      "    val_FPs        : [   0    0 1717 4190    6   27    0 3004    0    0]\n",
      "    val_FNs        : [1016  990  839  518 1007  999  981  570 1018 1006]\n",
      "    val_accuracy   : 0.1056\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7444 0.5292 0.8987 0.8974 0.9019 0.6426 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8211200000000002\n",
      "    val_precision  : [0.         0.         0.08670213 0.1016295  0.         0.1\n",
      " 0.         0.12163743 0.         0.        ]\n",
      "    val_precision_mean: 0.04099690571330581\n",
      "    val_recall     : [0.         0.         0.16267465 0.47782258 0.         0.00299401\n",
      " 0.         0.42190669 0.         0.        ]\n",
      "    val_recall_mean: 0.10653979370317797\n",
      "    val_predicted_class_distribution: [   0    0 1880 4664    6   30    0 3420    0    0]\n",
      "    val_f1         : [0.         0.         0.11311589 0.16760962 0.         0.00581395\n",
      " 0.         0.18883341 0.         0.        ]\n",
      "    val_f1_mean    : 0.04753728723226297\n",
      "    val_loss       : 2.2858924865722656\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [0/196 (0%)] Loss: 2.303221\n",
      "Train Epoch: 20 [48/196 (24%)] Loss: 2.304214\n",
      "Train Epoch: 20 [96/196 (49%)] Loss: 2.303031\n",
      "Train Epoch: 20 [144/196 (73%)] Loss: 2.298395\n",
      "Train Epoch: 20 [192/196 (98%)] Loss: 2.310194\n",
      "    epoch          : 20\n",
      "    val_TP         : [  0   0 164 473   0   3   0 416   0   0]\n",
      "    val_TN         : [8984 9010 7281 4822 8987 8971 9019 6006 8982 8994]\n",
      "    val_FPs        : [   0    0 1717 4186    6   27    0 3008    0    0]\n",
      "    val_FNs        : [1016  990  838  519 1007  999  981  570 1018 1006]\n",
      "    val_accuracy   : 0.1056\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7445 0.5295 0.8987 0.8974 0.9019 0.6422 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8211200000000002\n",
      "    val_precision  : [0.         0.         0.08718767 0.10152393 0.         0.1\n",
      " 0.         0.12149533 0.         0.        ]\n",
      "    val_precision_mean: 0.04102069254121246\n",
      "    val_recall     : [0.         0.         0.16367265 0.47681452 0.         0.00299401\n",
      " 0.         0.42190669 0.         0.        ]\n",
      "    val_recall_mean: 0.10653878765076666\n",
      "    val_predicted_class_distribution: [   0    0 1881 4659    6   30    0 3424    0    0]\n",
      "    val_f1         : [0.         0.         0.11377038 0.167404   0.         0.00581395\n",
      " 0.         0.18866213 0.         0.        ]\n",
      "    val_f1_mean    : 0.04756504623781977\n",
      "    val_loss       : 2.285886526107788\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [0/196 (0%)] Loss: 2.300153\n",
      "Train Epoch: 21 [48/196 (24%)] Loss: 2.303140\n",
      "Train Epoch: 21 [96/196 (49%)] Loss: 2.312511\n",
      "Train Epoch: 21 [144/196 (73%)] Loss: 2.298461\n",
      "Train Epoch: 21 [192/196 (98%)] Loss: 2.304595\n",
      "    epoch          : 21\n",
      "    val_TP         : [  0   0 165 473   0   3   0 417   0   0]\n",
      "    val_TN         : [8984 9010 7279 4825 8987 8971 9019 6007 8982 8994]\n",
      "    val_FPs        : [   0    0 1719 4183    6   27    0 3007    0    0]\n",
      "    val_FNs        : [1016  990  837  519 1007  999  981  569 1018 1006]\n",
      "    val_accuracy   : 0.1058\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7444 0.5298 0.8987 0.8974 0.9019 0.6424 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.8211600000000001\n",
      "    val_precision  : [0.         0.         0.08757962 0.10158935 0.         0.1\n",
      " 0.         0.12178738 0.         0.        ]\n",
      "    val_precision_mean: 0.04109563480910028\n",
      "    val_recall     : [0.         0.         0.16467066 0.47681452 0.         0.00299401\n",
      " 0.         0.42292089 0.         0.        ]\n",
      "    val_recall_mean: 0.1067400079282644\n",
      "    val_predicted_class_distribution: [   0    0 1884 4656    6   30    0 3424    0    0]\n",
      "    val_f1         : [0.         0.         0.11434511 0.16749292 0.         0.00581395\n",
      " 0.         0.18911565 0.         0.        ]\n",
      "    val_f1_mean    : 0.04767676319390154\n",
      "    val_loss       : 2.2858805656433105\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [0/196 (0%)] Loss: 2.310813\n",
      "Train Epoch: 22 [48/196 (24%)] Loss: 2.308777\n",
      "Train Epoch: 22 [96/196 (49%)] Loss: 2.303613\n",
      "Train Epoch: 22 [144/196 (73%)] Loss: 2.310895\n",
      "Train Epoch: 22 [192/196 (98%)] Loss: 2.307427\n",
      "    epoch          : 22\n",
      "    val_TP         : [  0   0 166 473   0   3   0 417   0   0]\n",
      "    val_TN         : [8984 9010 7277 4825 8987 8971 9019 6010 8982 8994]\n",
      "    val_FPs        : [   0    0 1721 4183    6   27    0 3004    0    0]\n",
      "    val_FNs        : [1016  990  836  519 1007  999  981  569 1018 1006]\n",
      "    val_accuracy   : 0.1059\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7443 0.5298 0.8987 0.8974 0.9019 0.6427 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.82118\n",
      "    val_precision  : [0.         0.         0.08797032 0.10158935 0.         0.1\n",
      " 0.         0.12189418 0.         0.        ]\n",
      "    val_precision_mean: 0.04114538533309093\n",
      "    val_recall     : [0.         0.         0.16566866 0.47681452 0.         0.00299401\n",
      " 0.         0.42292089 0.         0.        ]\n",
      "    val_recall_mean: 0.10683980832746598\n",
      "    val_predicted_class_distribution: [   0    0 1887 4656    6   30    0 3421    0    0]\n",
      "    val_f1         : [0.         0.         0.11491866 0.16749292 0.         0.00581395\n",
      " 0.         0.18924438 0.         0.        ]\n",
      "    val_f1_mean    : 0.047746991224477876\n",
      "    val_loss       : 2.285875082015991\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [0/196 (0%)] Loss: 2.305113\n",
      "Train Epoch: 23 [48/196 (24%)] Loss: 2.310614\n",
      "Train Epoch: 23 [96/196 (49%)] Loss: 2.301277\n",
      "Train Epoch: 23 [144/196 (73%)] Loss: 2.305975\n",
      "Train Epoch: 23 [192/196 (98%)] Loss: 2.304370\n",
      "    epoch          : 23\n",
      "    val_TP         : [  0   0 167 472   0   3   0 417   0   0]\n",
      "    val_TN         : [8984 9010 7272 4826 8987 8970 9019 6015 8982 8994]\n",
      "    val_FPs        : [   0    0 1726 4182    6   28    0 2999    0    0]\n",
      "    val_FNs        : [1016  990  835  520 1007  999  981  569 1018 1006]\n",
      "    val_accuracy   : 0.1059\n",
      "    val_per_class_accuracy: [0.8984 0.901  0.7439 0.5298 0.8987 0.8973 0.9019 0.6432 0.8982 0.8994]\n",
      "    val_per_class_accuracy_mean: 0.82118\n",
      "    val_precision  : [0.         0.         0.08821976 0.10141813 0.         0.09677419\n",
      " 0.         0.1220726  0.         0.        ]\n",
      "    val_precision_mean: 0.04084846850171627\n",
      "    val_recall     : [0.         0.         0.16666667 0.47580645 0.         0.00299401\n",
      " 0.         0.42292089 0.         0.        ]\n",
      "    val_recall_mean: 0.10683880227505468\n",
      "    val_predicted_class_distribution: [   0    0 1893 4654    6   31    0 3416    0    0]\n",
      "    val_f1         : [0.         0.         0.11537133 0.16719802 0.         0.00580833\n",
      " 0.         0.18945934 0.         0.        ]\n",
      "    val_f1_mean    : 0.047783700810519095\n",
      "    val_loss       : 2.28587007522583\n",
      "    lr             : (1e-06,)\n",
      "Saving checkpoint: saved/cifar10/resnet18/explainer/sift_descriptor_histogram/hparam_search/0525_102954/trials/lr_1e-06-wd_0/models/model_best.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(TPs / (TPs + FPs))\n",
      "/n/fs/ac-alignment/explain-alignment/src/model/metric.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(2 * precisions * recalls / (precisions + recalls))\n",
      "Exception ignored in: <function _releaseLock at 0x7ff2d93d58a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/fs/ac-project/anaconda3/envs/model-correlation/lib/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 1209589) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/model-correlation/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/model-correlation/lib/python3.11/multiprocessing/queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(config\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_descriptors_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_descriptors_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Restore model\u001b[39;00m\n\u001b[1;32m     44\u001b[0m model_restore_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(config\u001b[38;5;241m.\u001b[39msave_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_best.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/n/fs/ac-alignment/explain-alignment/src/train.py:113\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(config, train_data_loader, val_data_loader, seed)\u001b[0m\n\u001b[1;32m    104\u001b[0m     lr_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    106\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, criterion, metrics, optimizer,\n\u001b[1;32m    107\u001b[0m                   config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    108\u001b[0m                   device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    109\u001b[0m                   data_loader\u001b[38;5;241m=\u001b[39mtrain_data_loader,\n\u001b[1;32m    110\u001b[0m                   valid_data_loader\u001b[38;5;241m=\u001b[39mval_data_loader,\n\u001b[1;32m    111\u001b[0m                   lr_scheduler\u001b[38;5;241m=\u001b[39mlr_scheduler)\n\u001b[0;32m--> 113\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/n/fs/ac-alignment/explain-alignment/src/trainer/base_trainer.py:64\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m not_improved_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# save logged informations into log dict\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     log \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch}\n",
      "File \u001b[0;32m/n/fs/ac-alignment/explain-alignment/src/trainer/trainer.py:47\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     45\u001b[0m train_predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     46\u001b[0m train_targets \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader):\n\u001b[1;32m     48\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/model-correlation/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/model-correlation/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/model-correlation/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/n/fs/ac-project/anaconda3/envs/model-correlation/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 1209589) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# best = {\n",
    "#     'lr': -1,\n",
    "#     'wd': -1,\n",
    "#     'val_acc': -1\n",
    "# }\n",
    "# n_trials = len(learning_rates) * len(weight_decays)\n",
    "# trial_idx = 1\n",
    "# timestamp = datetime.now().strftime(r'%m%d_%H%M%S')\n",
    "\n",
    "# # Logging\n",
    "# log_path = os.path.join(config_json['trainer']['save_dir'], timestamp, 'log.txt')\n",
    "# ensure_dir(os.path.dirname(log_path))\n",
    "# informal_log(\"Hyperparameter search\", log_path)\n",
    "# informal_log(\"Learning rates: {}\".format(learning_rates), log_path)\n",
    "# informal_log(\"Weight decays: {}\".format(weight_decays), log_path)\n",
    "\n",
    "# # Debug mode\n",
    "# if debug:\n",
    "#     config_json['trainer']['epochs'] = 1\n",
    "    \n",
    "# for lr in learning_rates:\n",
    "#     for wd in weight_decays:\n",
    "#         # Update config json\n",
    "#         config_json['optimizer']['args'].update({\n",
    "#             'lr': lr,\n",
    "#             'weight_decay': wd\n",
    "#         })\n",
    "        \n",
    "#         # Create run ID for trial\n",
    "#         itr_timestamp = datetime.now().strftime(r'%m%d_%H%M%S')\n",
    "#         informal_log(\"[{}] Trial {}/{}: LR = {} WD = {}\".format(\n",
    "#             itr_timestamp, trial_idx, n_trials, lr, wd), log_path)\n",
    "#         run_id = os.path.join(timestamp, 'trials', 'lr_{}-wd_{}'.format(lr, wd))\n",
    "#         config = ConfigParser(config_json, run_id=run_id)\n",
    "#         print(config.config['optimizer']['args'])\n",
    "        \n",
    "#         # Train model\n",
    "#         model = train_fn(\n",
    "#             config=config, \n",
    "#             train_data_loader=train_descriptors_dataloader,\n",
    "#             val_data_loader=test_descriptors_dataloader)\n",
    "        \n",
    "#         # Restore model\n",
    "#         model_restore_path = os.path.join(config.save_dir, 'model_best.pth')\n",
    "        \n",
    "#         model.restore_model(model_restore_path)\n",
    "#         print(\"restored model\")\n",
    "#         # Run on validation set using predict function\n",
    "#         device, device_ids = prepare_device(config_json['n_gpu'])\n",
    "#         metric_fns = [getattr(module_metric, met) for met in config_json['metrics']]\n",
    "#         loss_fn = getattr(module_loss, config_json['loss'])\n",
    "#         trial_path = os.path.dirname(os.path.dirname(model_restore_path))\n",
    "#         output_save_path = os.path.join(trial_path, \"val_outputs.pth\")\n",
    "#         log_save_path = os.path.join(trial_path, \"val_metrics.pth\")\n",
    "        \n",
    "#         validation_data = predict(\n",
    "#             data_loader=test_descriptors_dataloader,\n",
    "#             model=model,\n",
    "#             metric_fns=metric_fns,\n",
    "#             device=device,\n",
    "#             loss_fn=loss_fn,\n",
    "#             output_save_path=output_save_path,\n",
    "#             log_save_path=log_save_path)\n",
    "       \n",
    "#         # Obtain accuracy and compare to previous best\n",
    "#         print(validation_data['metrics'].keys())\n",
    "#         val_accuracy = validation_data['metrics']['accuracy']\n",
    "#         if val_accuracy > best['val_acc']:\n",
    "#             best.update({\n",
    "#                 'lr': lr,\n",
    "#                 'wd': wd,\n",
    "#                 'val_acc': val_accuracy\n",
    "#             })\n",
    "#             informal_log(\"Best accuracy of {:.3f} with lr={} and wd={}\".format(val_accuracy, lr, wd), log_path)\n",
    "#             informal_log(\"Trial path: {}\".format(trial_path), log_path)\n",
    "#             # Copy model and outputs to 1 directory for easy access\n",
    "#             best_save_dir = os.path.join(os.path.dirname(os.path.dirname(trial_path)), 'best')\n",
    "#             ensure_dir(best_save_dir)\n",
    "#             best_outputs_save_path = os.path.join(best_save_dir, 'outputs.pth')\n",
    "#             best_model_save_path = os.path.join(best_save_dir, 'model.pth')\n",
    "#             torch.save(validation_data['logits'], best_outputs_save_path)\n",
    "#             model.save_model(best_model_save_path)\n",
    "#             informal_log(\"Saved model and outputs to {}\".format(best_save_dir), log_path)\n",
    "            \n",
    "            \n",
    "#         trial_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538e5b3-29b9-47bb-9534-25288dae9dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-correlation",
   "language": "python",
   "name": "model-correlation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
