{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given a 365 way scene classifier, obtain logits for 16-way scene category classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "from utils.places365_pred_utils import get_class_category_dict\n",
    "from utils.utils import ensure_dir, read_json\n",
    "from utils.model_utils import prepare_device\n",
    "from datasets.datasets import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "places365_dir= os.path.join('data', 'Places365')\n",
    "index_path = os.path.join(places365_dir, 'places365_val.txt')\n",
    "image_dir = os.path.join(places365_dir, 'val_256')\n",
    "\n",
    "train_split = 0.6\n",
    "seed = 0\n",
    "\n",
    "data_save_dir = os.path.join('data', 'places365_categories')\n",
    "data_save_path = os.path.join(data_save_dir, 'places365_imagelabels.pth')\n",
    "\n",
    "config_path = os.path.join('configs', 'learn_category_classifier_resnet_places365.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Places 365 into train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path data/places365_categories/places365_imagelabels.pth exists. Aborting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36500it [00:10, 3325.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scene and scene category labels\n",
      "Split train/val (0.6/0.4)\n",
      "Saved data to data/places365_categories/places365_imagelabels.pth\n"
     ]
    }
   ],
   "source": [
    "# Run setup script if not already\n",
    "if os.path.exists(data_save_path):\n",
    "    sys.path.insert(0, 'setup')\n",
    "    from setup_places365_categories import setup_places365_categories\n",
    "    setup_places365_categories(\n",
    "        image_dir=image_dir,\n",
    "        index_path=index_path,\n",
    "        train_split=train_split,\n",
    "        data_save_path=data_save_path,\n",
    "        seed=seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features of `val_train` and `val_val` partitions using Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join('configs', 'save_features_places_resnet_places365val.json')\n",
    "from save_features import save_features\n",
    "\n",
    "save_features(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features and labels for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['scene_labels', 'scene_category_labels', 'val_train', 'val_val'])\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join('data', 'places365_categories', 'places365_imagelabels.pth')\n",
    "features_dir = os.path.join('saved', 'Places365_val', '0509_161413')\n",
    "train_features_path = os.path.join(features_dir, 'val_train_features.pth')\n",
    "val_features_path = os.path.join(features_dir, 'val_val_features.pth')\n",
    "\n",
    "# Load labels\n",
    "data = torch.load(data_path)\n",
    "train_paths = data['val_train']\n",
    "val_paths = data['val_val']\n",
    "category_labels = data['scene_category_labels']\n",
    "train_category_labels = [category_labels[path] for path in train_paths]\n",
    "val_category_labels = [category_labels[path] for path in val_paths]\n",
    "\n",
    "# Load features\n",
    "train_features_dict = torch.load(train_features_path)\n",
    "val_features_dict = torch.load(val_features_path)\n",
    "\n",
    "# Sanity checks for elementwise correspondence\n",
    "for idx, path in enumerate(train_features_dict['paths']):\n",
    "    assert path == train_paths[idx]\n",
    "for idx, path in enumerate(val_features_dict['paths']):\n",
    "    assert path == val_paths[idx]\n",
    "\n",
    "train_features = train_features_dict['features']\n",
    "val_features = val_features_dict['features']\n",
    "\n",
    "# Length sanity checks\n",
    "assert len(train_features) == len(train_category_labels)\n",
    "assert len(val_features) == len(val_category_labels)\n",
    "\n",
    "print(\"Loaded {} samples for training and {} samples for validation\".format(\n",
    "    len(train_features), len(val_features)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 ('model-correlation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c579736b944d6d0768ad80dbc3e033126adf2082032258477813cfb04cf1061b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
