{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given a 365 way scene classifier, obtain logits for 16-way scene category classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "from utils.places365_pred_utils import get_class_category_dict\n",
    "from utils.utils import ensure_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Places 365 into train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "places365_path_dirpath = os.path.join('data', 'Places365')\n",
    "index_path = os.path.join(places365_path_dirpath, 'places365_val.txt')\n",
    "train_split = 0.6\n",
    "seed = 0 \n",
    "\n",
    "data_save_dir = os.path.join('data', 'places365_categories')\n",
    "data_save_path = os.path.join(data_save_dir, 'places365_imagelabels.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21900 14600\n",
      "                     filename  label\n",
      "0  Places365_val_00000001.jpg    165\n",
      "1  Places365_val_00000002.jpg    358\n",
      "2  Places365_val_00000003.jpg     93\n",
      "3  Places365_val_00000004.jpg    164\n",
      "4  Places365_val_00000005.jpg    289\n",
      "Index(['filename', 'label'], dtype='object') Index(['filename', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load dictionary\n",
    "class_category_dict = get_class_category_dict()\n",
    "\n",
    "df = pd.read_csv(index_path, delimiter=' ', header=None)\n",
    "df = df.rename(columns={0: 'filename', 1: 'label'})\n",
    "image_paths = df['filename'].tolist()\n",
    "scene_labels = df['label'].tolist()\n",
    "scene_category_labels = [class_category_dict[scene_label] for scene_label in scene_labels]\n",
    "\n",
    "# Store labels in dictionaries\n",
    "scene_labels_dict = {}\n",
    "scene_category_labels_dict = {}\n",
    "# Populate dictionaries\n",
    "for image_path, scene_label, scene_category_label in zip(image_paths, scene_labels, scene_category_labels):\n",
    "    scene_labels_dict[image_path] = scene_label\n",
    "    scene_category_labels_dict[image_path] = scene_category_label\n",
    "# Store in data object\n",
    "save_data = {}\n",
    "save_data['scene_labels'] = scene_labels_dict\n",
    "save_data['scene_category_labels'] = scene_category_labels_dict\n",
    "\n",
    "\n",
    "# Randomly split val_train and val_val\n",
    "train_df = df.sample(frac=train_split, random_state=seed)\n",
    "val_df = df.drop(train_df.index)\n",
    "print(len(train_df), len(val_df))\n",
    "print(df[0:5])\n",
    "\n",
    "print(train_df.columns, val_df.columns)\n",
    "\n",
    "# Assert no overlap between train and val\n",
    "assert len(pd.merge(train_df, val_df, how='inner', on=['filename', 'label'])) == 0\n",
    "\n",
    "# Store image paths to save data\n",
    "save_data['val_train'] = train_df['filename'].tolist()\n",
    "save_data['val_val'] = val_df['filename'].tolist()\n",
    "\n",
    "# Sanity checks\n",
    "for image_path in save_data['val_train']:\n",
    "    assert image_path in save_data['scene_labels']\n",
    "    assert image_path in save_data['scene_category_labels']\n",
    "for image_path in save_data['val_val']:\n",
    "    assert image_path in save_data['scene_labels']\n",
    "    assert image_path in save_data['scene_category_labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to data/places365_categories/places365_imagelabels.pth\n"
     ]
    }
   ],
   "source": [
    "ensure_dir(data_save_dir)\n",
    "if os.path.exists(data_save_path):\n",
    "    print(\"Path {} exists. Aborting\".format(data_save_path))\n",
    "else:\n",
    "    torch.save(save_data, data_save_path)\n",
    "    print(\"Saved data to {}\".format(data_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 ('model-correlation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c579736b944d6d0768ad80dbc3e033126adf2082032258477813cfb04cf1061b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
