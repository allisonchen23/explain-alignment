{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d0bf6f-04d5-4667-b077-3c1fb8ce2e52",
   "metadata": {},
   "source": [
    "Process inputs for different types of explainers\n",
    "* pixel-based (of normalized images)\n",
    "    * RGB ((3 x H x W)-dimension vectors)\n",
    "    * intensity ((H x W)-dimension vectors\n",
    "* SIFT feature based\n",
    "    * set parameters: \n",
    "        * sigma : scaling parameter (smaller is smaller Gaussian blurs)\n",
    "        * K : number of clusters to form histogram\n",
    "* concept-based\n",
    "    * labelled\n",
    "        * set parameters:\n",
    "            * tau : occurrence threshold (minimum number of images in the training set that concept must occur in)\n",
    "    * discovery\n",
    "        * currently not implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059c1ec9-d442-4353-a670-79a4587f549e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "import datasets.datasets as module_data\n",
    "from utils.utils import ensure_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c97c1e-694f-41f8-bb72-bbb0bfa89d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASETS_AVAILABLE = ['cifar', 'ADE20K']\n",
    "INPUT_TYPES_AVAILABLE = ['pixel', 'SIFT', 'concept']\n",
    "PIXEL_TYPES_AVAILBLE = ['RGB', 'intensity']\n",
    "SAVE_ROOT = 'data/explainer_inputs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab889776-faa6-4e7b-8b1b-fbc95627966f",
   "metadata": {},
   "source": [
    "## Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd0170c-d656-4955-b27a-e8c7520ed60c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT-based explainer using sigma=1.6; K=500; stride=2\n",
      "Loading descriptors from saved/cifar10/sift_32_32_sigma1.6/dense_stride_2/sift_keypoints_descriptors.pth\n",
      "Loading KMeans from saved/cifar10/sift_32_32_sigma1.6/dense_stride_2/minibatch_kmeans/500means/descriptor_kmeans.pth\n",
      "Created save directory at data/explainer_inputs/cifar/SIFT/sigma_1.6/stride_2/K_500\n",
      "Loading descriptors and KMeans...\n"
     ]
    }
   ],
   "source": [
    "dataset_type = 'cifar'\n",
    "input_type = 'SIFT'\n",
    "\n",
    "# Params for pixel-based explainers\n",
    "pixel_type = 'intensity'\n",
    "\n",
    "# Params for SIFT-based explainers\n",
    "sigma = 1.6\n",
    "K = 500\n",
    "stride = 2\n",
    "SIFT_descriptors_path = 'saved/cifar10/sift_32_32_sigma1.6/dense_stride_2/sift_keypoints_descriptors.pth'\n",
    "SIFT_KMeans_path = 'saved/cifar10/sift_32_32_sigma1.6/dense_stride_2/minibatch_kmeans/500means/descriptor_kmeans.pth'\n",
    "\n",
    "save_dir = os.path.join(SAVE_ROOT, dataset_type, input_type)\n",
    "# Check inputs are valid\n",
    "assert dataset_type in DATASETS_AVAILABLE, \"Dataset type '{}' not supported. Try one of {}\".format(dataset_type, DATASET_TYPES_AVAILABLE)\n",
    "assert input_type in INPUT_TYPES_AVAILABLE\n",
    "\n",
    "if input_type == 'pixel':\n",
    "    print(\"Pixel-based explainer using {} inputs\".format(pixel_type))\n",
    "    save_dir = os.path.join(save_dir, pixel_type)\n",
    "elif input_type == 'SIFT':\n",
    "    assert str(sigma) in SIFT_descriptors_path and str(sigma) in SIFT_KMeans_path\n",
    "    assert str(K) in SIFT_KMeans_path\n",
    "    assert str(stride) in SIFT_descriptors_path and str(stride) in SIFT_KMeans_path\n",
    "    print(\"SIFT-based explainer using sigma={}; K={}; stride={}\".format(sigma, K, stride))\n",
    "    print(\"Loading descriptors from {}\".format(SIFT_descriptors_path))\n",
    "    print(\"Loading KMeans from {}\".format(SIFT_KMeans_path))\n",
    "    save_dir = os.path.join(save_dir, 'sigma_{}'.format(sigma), 'stride_{}'.format(stride), 'K_{}'.format(K))\n",
    "else:\n",
    "    raise ValueError(\"Explainer type '{}' not supported. Try one of {}\".format(\n",
    "        input_type, INPUT_TYPES_AVAILABLE))\n",
    "\n",
    "# Create save directory\n",
    "ensure_dir(save_dir)\n",
    "print(\"Created save directory at {}\".format(save_dir))\n",
    "\n",
    "# Obtain paths for data to be processed\n",
    "if dataset_type == 'cifar':\n",
    "    dataset_dir = os.path.join('data', 'cifar10-processed')\n",
    "    if input_type == 'pixel':\n",
    "        paths = {\n",
    "            'dataset_dir': dataset_dir\n",
    "        }\n",
    "    elif input_type == 'SIFT':\n",
    "        print(\"Loading descriptors and KMeans...\")\n",
    "        SIFT_descriptors = torch.load(SIFT_descriptors_path)\n",
    "        SIFT_KMeans = torch.load(SIFT_KMeans_path)\n",
    "        # paths = {\n",
    "        #     'descriptor_path': SIFT_descriptors_path,\n",
    "        #     'KMeans_path': SIFT_KMeans_path\n",
    "        # }\n",
    "    IMAGE_HEIGHT = 32\n",
    "    IMAGE_WIDTH = 32\n",
    "    N_TRAIN = 50000\n",
    "    N_TEST = 10000\n",
    "else: \n",
    "    raise ValueError(\"Dataset type '{}' not supported. Try one of {}\".format(dataset_type, DATASET_TYPES_AVAILABLE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1626f-9a07-46b3-9ddc-91b2614a647f",
   "metadata": {},
   "source": [
    "## Process the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b26b9-4d7d-4814-a3ee-a660b73d0409",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcdad0b2-6cf0-400c-83e7-2c8dfa038f42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cifar_dataloaders(dataset_dir,\n",
    "                          normalize,\n",
    "                          batch_size,\n",
    "                          num_workers):\n",
    "    train_dataset = module_data.CIFAR10TorchDataset(\n",
    "        dataset_dir=dataset_dir,\n",
    "        split='train',\n",
    "        normalize=normalize)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers)\n",
    "\n",
    "    test_dataset = module_data.CIFAR10TorchDataset(\n",
    "        dataset_dir=dataset_dir,\n",
    "        split='test',\n",
    "        normalize=normalize)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers)\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "def flatten_images(train_dataloader,\n",
    "                   test_dataloader,\n",
    "                   pixel_type):\n",
    "    '''\n",
    "    Arg(s):\n",
    "        train_dataloader : torch.utils.data.DataLoader\n",
    "            Dataloader for training dataset\n",
    "        test_dataloader : torch.utils.data.DataLoader\n",
    "            Dataloader for testing dataset\n",
    "        pixel_type : str\n",
    "            'RGB' or 'intensity'\n",
    "    Returns:\n",
    "        tuple(np.array, np.array) : flattened inputs for train and test respectively\n",
    "    '''\n",
    "    assert pixel_type in PIXEL_TYPES_AVAILBLE\n",
    "    \n",
    "    splits = [('train', train_dataloader), ('test', test_dataloader)]\n",
    "    flattened_data = {}\n",
    "    # Iterate through splits\n",
    "    for split_name, split_dataloader in splits:\n",
    "        print(\"Flattening {} data based on {}\".format(split_name, pixel_type))\n",
    "        split_flattened = []\n",
    "        # Iterate through batches\n",
    "        for image, label in tqdm(split_dataloader):\n",
    "            if pixel_type == 'intensity':\n",
    "                image = torch.mean(image, dim=1) # RGB Channel\n",
    "            flattened_image = torch.flatten(image, start_dim=1)\n",
    "            split_flattened.append(flattened_image)\n",
    "        # Concatenate and convert to numpy arrays\n",
    "        split_flattened = torch.cat(split_flattened, dim=0)\n",
    "        split_flattened = split_flattened.numpy()\n",
    "        flattened_data[split_name] = split_flattened\n",
    "    \n",
    "    return flattened_data['train'], flattened_data['test']\n",
    "\n",
    "def process_pixel_inputs(dataset_type,\n",
    "                         dataset_dir,\n",
    "                         pixel_type,\n",
    "                         save_path):\n",
    "    '''\n",
    "    Given a dataset, and a pixel type ('RGB' or 'intensity') flatten images in each split and return as 1D vectors\n",
    "    \n",
    "    Arg(s):\n",
    "        dataset_type : str\n",
    "            Dataset name. One of ['cifar', 'ADE20K']\n",
    "        paths : dict{str : str}\n",
    "            Path to directory where images are stored\n",
    "        pixel_type : str\n",
    "            'RGB' or 'intensity'\n",
    "        save_path : str or None\n",
    "            \n",
    "    '''\n",
    "    batch_size = 256\n",
    "    num_workers = 8\n",
    "    normalize = True\n",
    "    \n",
    "    # Assert file doesn't already exist at save_path\n",
    "    assert not os.path.exists(save_path), \"File already exists at {}. Please remove it\".format(save_path)\n",
    "    \n",
    "    if dataset_type == 'cifar':\n",
    "        train_dataloader, test_dataloader = get_cifar_dataloaders(\n",
    "            dataset_dir=dataset_dir,\n",
    "            normalize=normalize,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers)\n",
    "        train_flattened, test_flattened = flatten_images(\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            pixel_type=pixel_type)\n",
    "        \n",
    "        # Perform checks on shape given CIFAR images are 32 x 32\n",
    "        n_train, train_dim = train_flattened.shape\n",
    "        n_test, test_dim = test_flattened.shape\n",
    "        if pixel_type == 'RGB':\n",
    "            assert train_dim == 3 * IMAGE_HEIGHT * IMAGE_WIDTH, \\\n",
    "                \"Expected training data to have {}-dims. Received {}.\".format(\n",
    "                3 * IMAGE_HEIGHT * IMAGE_WIDTH, train_flattened.shape[1])\n",
    "            assert test_dim == 3 * IMAGE_HEIGHT * IMAGE_WIDTH, \\\n",
    "                \"Expected test data to have {}-dims. Received {}.\".format(\n",
    "                3 * IMAGE_HEIGHT * IMAGE_WIDTH, test_flattened.shape[1])\n",
    "            \n",
    "        elif pixel_type == 'intensity':\n",
    "            assert train_dim == IMAGE_HEIGHT * IMAGE_WIDTH, \\\n",
    "                \"Expected training data to have {}-dims. Received {}.\".format(\n",
    "                IMAGE_HEIGHT * IMAGE_WIDTH, train_flattened.shape[1])\n",
    "            assert test_dim == IMAGE_HEIGHT * IMAGE_WIDTH, \\\n",
    "                \"Expected test data to have {}-dims. Received {}.\".format(\n",
    "                IMAGE_HEIGHT * IMAGE_WIDTH, test_flattened.shape[1])\n",
    "        # Check number of samples in train/test\n",
    "        assert n_train == N_TRAIN and n_test == N_TEST\n",
    "        \n",
    "        # Save file\n",
    "        explainer_inputs = {\n",
    "            'train': train_flattened,\n",
    "            'test': test_flattened\n",
    "        }\n",
    "        torch.save(explainer_inputs, save_path)\n",
    "        print(\"Saved {} flattened cifar images to {}\".format(pixel_type, save_path))\n",
    "    else:\n",
    "        raise ValueError(\"Dataset type '{}' not supported. Try one of {}\".format(dataset_type, DATASET_TYPES_AVAILABLE))\n",
    "    return train_flattened, test_flattened\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b97c032-e262-4cf9-9789-066821986df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_SIFT_inputs(dataset_type,\n",
    "                        descriptors,\n",
    "                        KMeans,\n",
    "                        save_path):\n",
    "    '''\n",
    "    Given paths to descriptors and the KMeans clustering, create histograms for each image in train/test\n",
    "    \n",
    "    '''\n",
    "    # Assert file doesn't already exist at save_path\n",
    "    assert not os.path.exists(save_path), \"File already exists at {}. Please remove it\".format(save_path)\n",
    "    \n",
    "    assert 'train' in descriptors.keys(), \"Expected key 'train' in descriptors. Only found {}\".format(descriptors.keys())\n",
    "    assert 'test' in descriptors.keys(), \"Expected key 'test' in descriptors. Only found {}\".format(descriptors.keys())\n",
    "    \n",
    "    train_descriptors = descriptors['train']['descriptors']\n",
    "    test_descriptors = descriptors['test']['descriptors']\n",
    "    \n",
    "    K = KMeans.cluster_centers_.shape[0]\n",
    "    splits = [('train', train_descriptors), ('test', test_descriptors)]\n",
    "    histogram_vectors = {}\n",
    "    \n",
    "    for split_name, split_descriptors in splits:\n",
    "        split_histogram_vectors = []\n",
    "        for idx, image_descriptors in enumerate(tqdm(split_descriptors, total=len(split_descriptors))):\n",
    "\n",
    "            n_descriptors = len(image_descriptors)\n",
    "            descriptor_clusters = KMeans.predict(image_descriptors)\n",
    "            histogram = np.zeros(K)\n",
    "            for cluster_idx in descriptor_clusters:\n",
    "                histogram[cluster_idx] += 1 / n_descriptors  # add 1/n_descriptors bc histogram will be normalized\n",
    "\n",
    "            split_histogram_vectors.append(histogram)\n",
    "        # Concatenate histograms to np array\n",
    "        split_histogram_vectors = np.stack(split_histogram_vectors, axis=0)\n",
    "\n",
    "        histogram_vectors[split_name] = split_histogram_vectors\n",
    "    torch.save(histogram_vectors, save_path)\n",
    "    print(\"Saved histogram of SIFT features from cifar images to {}\".format(save_path))\n",
    "    return histogram_vectors['train'], histogram_vectors['test']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e27b9-9aec-4b85-8231-3cda2df7d13b",
   "metadata": {},
   "source": [
    "### Call process inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f6d24fb-c038-4e63-9c10-241d90f0c0de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 50000/50000 [00:53<00:00, 927.53it/s]\n",
      "100%|████████████████████████████████████| 10000/10000 [00:10<00:00, 931.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved histogram of SIFT features from cifar images to data/explainer_inputs/cifar/SIFT/sigma_1.6/stride_2/K_500/cifar_SIFT_sigma_1.6_stride_2_K_500_explainer_inputs.pth\n"
     ]
    }
   ],
   "source": [
    "filename = '{}_{}'.format(dataset_type, input_type)\n",
    "if input_type == 'pixel':\n",
    "    filename = '{}_{}'.format(filename, pixel_type)\n",
    "elif input_type == 'SIFT':\n",
    "    filename = '{}_sigma_{}_stride_{}_K_{}'.format(filename, sigma, stride, K)\n",
    "else:\n",
    "    raise ValueError(\"Explainer type '{}' not supported. Try one of {}\".format(\n",
    "        input_type, INPUT_TYPES_AVAILABLE))\n",
    "filename = '{}_explainer_inputs.pth'.format(filename)\n",
    "save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "if input_type == 'pixel':\n",
    "    train_flattened, test_flattened = process_pixel_inputs(\n",
    "        dataset_type=dataset_type,\n",
    "        paths=paths,\n",
    "        pixel_type=pixel_type,\n",
    "        save_path=save_path)\n",
    "elif input_type == 'SIFT':\n",
    "    train_histograms, test_histograms = process_SIFT_inputs(\n",
    "        dataset_type=dataset_type,\n",
    "        descriptors=SIFT_descriptors,\n",
    "        KMeans=SIFT_KMeans,\n",
    "        save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f3177-fe7a-4914-955a-2e173b0be446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-correlation",
   "language": "python",
   "name": "model-correlation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
