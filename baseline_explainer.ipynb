{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a43608d-fba8-4ebf-80eb-9923937e810a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sys.path.insert(0, 'src')\n",
    "from utils.places365_pred_utils import get_class_category_dict, get_category_class_dict\n",
    "from utils.utils import ensure_dir, write_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671af142-39e5-457c-bc49-af4462c8800d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_ATTR = 1200  # Taken from Vikram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d4eff-6e6a-40cd-8cc9-10d6fad75ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load attributes and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4d23fd-1866-4364-ab5d-1ba1641cb51d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data keys: dict_keys(['train', 'val', 'test', 'labels'])\n",
      "(13326,) (4442,) (4442,)\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join('data', 'ade20k', 'ade20k_imagelabels.pth')\n",
    "save_dir = os.path.join('saved', 'ADE20K', '0501_105640')\n",
    "predictions_path = os.path.join(save_dir, '{}_logits_predictions.pth')\n",
    "\n",
    "data = torch.load(data_path)\n",
    "print(\"Data keys: {}\".format(data.keys()))\n",
    "train = torch.load(predictions_path.format('train'))\n",
    "train_paths = train['paths']\n",
    "train_predictions = train['predictions']\n",
    "\n",
    "val = torch.load(predictions_path.format('val'))\n",
    "val_paths = val['paths']\n",
    "val_logits = val['logits']\n",
    "val_predictions = val['predictions']\n",
    "\n",
    "test = torch.load(predictions_path.format('test'))\n",
    "test_paths = test['paths']\n",
    "test_predictions = test['predictions']\n",
    "\n",
    "print(train_predictions.shape, val_predictions.shape, test_predictions.shape)\n",
    "predictions = {\n",
    "    'train': train_predictions,\n",
    "    'val': val_predictions,\n",
    "    'test': test_predictions\n",
    "}\n",
    "paths = {\n",
    "    'train': train_paths,\n",
    "    'val': val_paths,\n",
    "    'test': test_paths\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e398647-6568-4d1d-b460-ea79e407e567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing attributes for train split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 13326/13326 [00:00<00:00, 92202.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing attributes for val split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████| 4442/4442 [00:00<00:00, 142337.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing attributes for test split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 4442/4442 [00:00<00:00, 130098.17it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_one_hot_attributes(data, paths):\n",
    "    splits = ['train', 'val', 'test']\n",
    "    attributes = {\n",
    "        'train': [],\n",
    "        'val': [], \n",
    "        'test': []\n",
    "    }\n",
    "    \n",
    "    for split in splits:\n",
    "        split_paths = paths[split]\n",
    "        print(\"Processing attributes for {} split\".format(split))\n",
    "        for path in tqdm(split_paths):\n",
    "            # Obtain attributes and covnvert to one hot\n",
    "            cur_attributes = data['labels'][path]\n",
    "            one_hot_attributes = np.zeros(N_ATTR)\n",
    "            one_hot_attributes[cur_attributes] = 1\n",
    "            attributes[split].append(one_hot_attributes)\n",
    "        attributes[split] = np.stack(attributes[split], axis=0)\n",
    "        \n",
    "    return attributes\n",
    "\n",
    "\n",
    "attributes = get_one_hot_attributes(data, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b8bfa7-eef9-4c1c-b60c-6fa593df2d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 concepts that occur > 150 times in training\n",
      "623 concepts that occur at all in training\n"
     ]
    }
   ],
   "source": [
    "train_attributes = attributes['train']\n",
    "counts = np.sum(train_attributes, axis=0)\n",
    "print(\"{} concepts that occur > 150 times in training\".format(len(np.where(counts > 150)[0])))\n",
    "print(\"{} concepts that occur at all in training\".format(len(np.nonzero(counts)[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad38fa7-4284-4e04-b04b-25c666307d5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Obtain attributes that are frequently occuring in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d281133f-ffb5-4a6f-a87d-44113f34f040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 examples have no more attributes\n",
      "8308/13326 examples affected\n",
      "3 examples have no more attributes\n",
      "2736/4442 examples affected\n",
      "3 examples have no more attributes\n",
      "2804/4442 examples affected\n"
     ]
    }
   ],
   "source": [
    "FREQUENCY_THRESH = 150\n",
    "n_samples = attributes['train'].shape[0]\n",
    "train_counts = np.sum(attributes['train'], axis=0)\n",
    "\n",
    "def obtain_frequent_attributes(cur_attributes, train_counts):\n",
    "\n",
    "    # Obtain one-hot encoding of attributes that exceed frequency threshold\n",
    "    freq_attributes_one_hot = np.where(train_counts > FREQUENCY_THRESH, 1, 0)\n",
    "    # Mask out infrequent attributes\n",
    "    freq_attributes = np.where(freq_attributes_one_hot == 1, cur_attributes, 0)\n",
    "    # freq_train_attributes = np.where(freq_attributes_one_hot == 1, attributes['train'], 0)\n",
    "    # freq_val_attributes = np.where(freq_attributes_one_hot == 1, attributes['val'], 0)\n",
    "    # freq_test_attributes = np.where(freq_attributes_one_hot == 1, attributes['test'], 0)\n",
    "\n",
    "    # Sanity checks\n",
    "    discarded_attributes_idxs = np.nonzero(np.where(train_counts < FREQUENCY_THRESH, 1, 0))[0]\n",
    "    kept_attributes_idxs = np.nonzero(train_counts > FREQUENCY_THRESH)[0]\n",
    "    assert (kept_attributes_idxs == np.nonzero(freq_attributes_one_hot)[0]).all()\n",
    "\n",
    "    zeroed_ctr = 0\n",
    "    ctr = 0\n",
    "    for idx, (orig, new) in enumerate(zip(cur_attributes, freq_attributes)):\n",
    "        # print(orig\n",
    "        if not (orig == new).all():\n",
    "            orig_idxs = np.nonzero(orig)[0]\n",
    "            new_idxs = np.nonzero(new)[0]\n",
    "            # Assert new idxs ONLY contains the kept attributes and none of discarded\n",
    "            assert len(np.intersect1d(new_idxs, discarded_attributes_idxs)) == 0\n",
    "            assert len(np.intersect1d(new_idxs, kept_attributes_idxs)) == len(new_idxs)\n",
    "            # Assert overlap with original indices is equal to new indices\n",
    "            assert (np.intersect1d(orig_idxs, new_idxs) == new_idxs).all()\n",
    "            if len(new_idxs) == 0:\n",
    "                zeroed_ctr += 1\n",
    "            ctr += 1\n",
    "    print(\"{} examples have no more attributes\".format(zeroed_ctr))\n",
    "    print(\"{}/{} examples affected\".format(ctr, len(cur_attributes)))\n",
    "    \n",
    "    return freq_attributes\n",
    "\n",
    "freq_attributes = {}\n",
    "for split in ['train', 'val', 'test']:\n",
    "    cur_freq_attributes = obtain_frequent_attributes(\n",
    "        cur_attributes=attributes[split],\n",
    "        train_counts = train_counts)\n",
    "    freq_attributes[split] = cur_freq_attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693f7e0-3e8d-4834-a0f3-880345f8fc14",
   "metadata": {},
   "source": [
    "#### Obtain scene category predictions and save to save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd38717-dc47-467b-b20f-fc573c656b77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved/ADE20K/0501_105640/train_scene_category_predictions.pth already exists.\n",
      "saved/ADE20K/0501_105640/val_scene_category_predictions.pth already exists.\n",
      "saved/ADE20K/0501_105640/test_scene_category_predictions.pth already exists.\n"
     ]
    }
   ],
   "source": [
    "scene_category_dict = get_class_category_dict()\n",
    "\n",
    "def get_scene_category_predictions(scene_predictions, scene_category_dict):\n",
    "    category_predictions = []\n",
    "    for scene_prediction in scene_predictions:\n",
    "        category_predictions.append(scene_category_dict[scene_prediction])\n",
    "    \n",
    "    category_predictions = np.array(category_predictions)\n",
    "    return category_predictions\n",
    "\n",
    "# Save category predictions in save_dir\n",
    "category_predictions = {}\n",
    "for split, split_predictions in predictions.items():\n",
    "    split_category_predictions = get_scene_category_predictions(\n",
    "        scene_predictions=split_predictions,\n",
    "        scene_category_dict=scene_category_dict)\n",
    "    \n",
    "    save_path = os.path.join(save_dir, '{}_scene_category_predictions.pth'.format(split))\n",
    "    if os.path.exists(save_path):\n",
    "        print(\"{} already exists.\".format(save_path))\n",
    "    else:\n",
    "        torch.save({'scene_category_predictions': split_category_predictions}, save_path)\n",
    "        print(\"Saved scene category predictions for {} to {}\".format(split, save_path))\n",
    "    category_predictions[split] = split_category_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c10b26-9497-4867-8e31-d2f9eb88cf4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Run hyperparameter search on logistic regression for linear model to predict classes from attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9624bc97-4510-471f-b8b9-ab62647e20c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hyperparam_search_l1(train_features, train_labels, val_features, val_labels, \n",
    "                      Cs = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 3, 5]):\n",
    "    best_clf = None\n",
    "    best_acc = 0\n",
    "    \n",
    "    for c in Cs:\n",
    "        clf = LogisticRegression(solver='liblinear', C=c, penalty='l1')\n",
    "        clf.fit(train_features, train_labels)\n",
    "        score = clf.score(val_features, val_labels)\n",
    "        if score>best_acc:\n",
    "            best_acc = score\n",
    "            best_clf = clf\n",
    "            print(\"Best accuracy: {} Regularization: {}\".format(score, c))\n",
    "    \n",
    "    return best_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a2e66-03f4-451b-bd1d-3dc153accb70",
   "metadata": {},
   "source": [
    "#### Predicting all 365 classes with all part/object attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecdfe93b-ef53-4cc0-85e0-dd9fb7386abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029941467807294012 0.001\n",
      "0.1154885186852769 0.005\n",
      "0.15038271049076993 0.01\n",
      "0.23660513282305268 0.05\n",
      "0.28140477262494373 0.1\n",
      "0.3685276902296263 0.5\n",
      "0.375056280954525 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_search_l1(\n",
    "    train_features=attributes['train'],\n",
    "    train_labels=train_predictions,\n",
    "    val_features=attributes['val'],\n",
    "    val_labels=val_predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3222903-b336-4e1f-bf1d-4bc21d0876d0",
   "metadata": {},
   "source": [
    "#### Predicting all  365 classes with part/object attributes that appear in >=150 training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "594d82ff-043e-4634-9fec-1411815020cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.029941467807294012 Regularization: 0.001\n",
      "Best accuracy: 0.1154885186852769 Regularization: 0.005\n",
      "Best accuracy: 0.14678072940117065 Regularization: 0.01\n",
      "Best accuracy: 0.20711391265195858 Regularization: 0.05\n",
      "Best accuracy: 0.24245835209365152 Regularization: 0.1\n",
      "Best accuracy: 0.285006753714543 Regularization: 0.5\n",
      "Best accuracy: 0.2915353444394417 Regularization: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_search_l1(\n",
    "    train_features=freq_train_attributes,\n",
    "    train_labels=train_predictions,\n",
    "    val_features=freq_val_attributes,\n",
    "    val_labels=val_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cddda3-30ad-4b29-868a-cf9b15730beb",
   "metadata": {},
   "source": [
    "#### Predict only 16 scene categories with all part/object attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40e57804-92da-40be-a274-bddb97e4ecfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.3275551553354345 Regularization: 0.001\n",
      "Best accuracy: 0.39756866276452046 Regularization: 0.005\n",
      "Best accuracy: 0.43876632147681227 Regularization: 0.01\n",
      "Best accuracy: 0.5538045925258892 Regularization: 0.05\n",
      "Best accuracy: 0.5839711841512832 Regularization: 0.1\n",
      "Best accuracy: 0.6226924808644755 Regularization: 0.5\n",
      "Best accuracy: 0.6292210715893741 Regularization: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_search_l1(\n",
    "    train_features=attributes['train'],\n",
    "    train_labels=category_predictions['train'],\n",
    "    val_features=attributes['val'],\n",
    "    val_labels=category_predictions['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b07d46-28d2-43a7-afea-b33058fe1979",
   "metadata": {},
   "source": [
    "#### Predict 16 scene categories with top attributes (appear in 150 or more training examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "951b77a0-bbef-45ce-9282-a248bad35f97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.3275551553354345 Regularization: 0.001\n",
      "Best accuracy: 0.39756866276452046 Regularization: 0.005\n",
      "Best accuracy: 0.43876632147681227 Regularization: 0.01\n",
      "Best accuracy: 0.5319675821701936 Regularization: 0.05\n",
      "Best accuracy: 0.5522287257991896 Regularization: 0.1\n",
      "Best accuracy: 0.5621341737955876 Regularization: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.5, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.5, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_search_l1(\n",
    "    train_features=freq_attributes['train'],\n",
    "    train_labels=category_predictions['train'],\n",
    "    val_features=freq_attributes['val'],\n",
    "    val_labels=category_predictions['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83cf4e4-5a83-4e11-9f5f-74f3e70cc8ff",
   "metadata": {},
   "source": [
    "### Obtain predictions of linear classifier on validation set (16 way classifier with only frequent attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4263c509-e66e-4c0f-a418-9e673a190e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5621341737955876\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "c = 0.5\n",
    "train_X = freq_attributes['train']\n",
    "val_X = freq_attributes['val']\n",
    "\n",
    "train_y = category_predictions['train']\n",
    "val_y = category_predictions['val']\n",
    "\n",
    "baseline_save_dir = os.path.join(save_dir, 'baseline_explainer')\n",
    "ensure_dir(baseline_save_dir)\n",
    "param_string = '16_class_freq_attr'\n",
    "\n",
    "incongruent_save_path = os.path.join(baseline_save_dir, 'incongruent_paths_{}.txt'.format(param_string))\n",
    "congruent_save_path = os.path.join(baseline_save_dir, 'congruent_paths_{}.txt'.format(param_string))\n",
    "\n",
    "# Create logistic regression classifier and predict for validation set\n",
    "logreg = LogisticRegression(solver='liblinear', C=c, penalty='l1')\n",
    "logreg.fit(train_X, train_y)\n",
    "\n",
    "logreg_category_predictions = logreg.predict(val_X)\n",
    "\n",
    "n_samples = len(val_y)\n",
    "assert len(logreg_category_predictions) == n_samples\n",
    "assert len(val_paths) == n_samples\n",
    "\n",
    "print(\"Accuracy: {}\".format(1 - np.count_nonzero(logreg_category_predictions != val_y) / n_samples))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0ea79-5ceb-4a40-a29f-0c6b17c34669",
   "metadata": {},
   "outputs": [],
   "source": [
    "incongruent_paths = []\n",
    "congruent_paths = []\n",
    "for logreg_pred, model_pred, image_path in tqdm(zip(logreg_category_predictions, val_y, val_paths)):\n",
    "    if logreg_pred != model_pred:\n",
    "        incongruent_paths.append(image_path)\n",
    "    else:\n",
    "        congruent_paths.append(image_path)\n",
    "\n",
    "for save_path, paths_list in zip([incongruent_save_path, congruent_save_path], [incongruent_paths, congruent_paths]):\n",
    "    if os.path.exists(save_path):\n",
    "        print(\"{} already exists\".format(save_path))\n",
    "    else:\n",
    "        write_lists(save_path, paths_list)\n",
    "        print(\"Saved {} paths to {}\".format(len(paths_list), save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b881a-1432-4a05-b131-f532a64c69ec",
   "metadata": {},
   "source": [
    "#### Obtain the pre-normalized output and normalized probabilities from the logistic regressor on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf6e3f3-9062-46f9-8adf-733c69c372be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -6.21541755  -9.57385951 -11.01464339  -8.19257013  -8.35659567\n",
      "  -2.3154842   -5.336674    -7.39402475  -2.75187164  -5.73843319\n",
      "  -3.09532866   0.10664419  -1.61541948  -4.4823798   -1.89333494\n",
      "  -2.06268626] [1.73180361e-03 6.03646460e-05 1.42916118e-05 2.40203346e-04\n",
      " 2.03873998e-04 7.80187178e-02 4.15828632e-03 5.33624900e-04\n",
      " 5.20836190e-02 2.78689906e-03 3.75992050e-02 4.57296199e-01\n",
      " 1.44002514e-01 9.70804106e-03 1.13634363e-01 9.79279926e-02] 1.0\n"
     ]
    }
   ],
   "source": [
    "outputs = logreg.decision_function(val_X)\n",
    "output_probabilities = logreg.predict_proba(val_X)\n",
    "print(outputs[0], output_probabilities[0], np.sum(output_probabilities[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedfb814-76e3-487c-b56c-7aed6ec75f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4442,)\n",
      "1103\n",
      "4437\n",
      "4434\n",
      "[ 8 15 15  2  2] [209 112 125  52  45]\n"
     ]
    }
   ],
   "source": [
    "def aggregate_category_logits(outputs, category_scene_dict, aggregation_mode='sum'):\n",
    "    '''\n",
    "    Given classifier outputs and scene mapper, aggregate logit outputs based on aggregation mode\n",
    "    '''\n",
    "    if aggregation_mode == 'sum':\n",
    "        agg_fn = np.sum\n",
    "    elif aggregation_mode == 'mean':\n",
    "        agg_fn = np.mean\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported aggregation mode '{}'\".format(aggregation_mode))\n",
    "    \n",
    "    aggregated_outputs = []\n",
    "    sorted_keys = sorted(list(category_scene_dict.keys()))\n",
    "    for category in sorted_keys:\n",
    "        # print(category)\n",
    "        scenes = category_scene_dict[category]\n",
    "        category_aggregated = agg_fn(outputs[:, scenes], axis=1)\n",
    "        # print(category_aggregated.shape)\n",
    "        aggregated_outputs.append(category_aggregated)\n",
    "        \n",
    "    aggregated_outputs = np.stack(aggregated_outputs, axis=1)\n",
    "    return aggregated_outputs\n",
    "\n",
    "\n",
    "category_scene_dict = get_category_class_dict()\n",
    "\n",
    "mean_category_logits = aggregate_category_logits(\n",
    "    outputs=val_logits,\n",
    "    category_scene_dict=category_scene_dict,\n",
    "    aggregation_mode='mean')\n",
    "\n",
    "mean_argmax = np.argmax(mean_category_logits, axis=1)\n",
    "print(mean_argmax.shape)\n",
    "sum_category_logits = aggregate_category_logits(\n",
    "    outputs=val_logits,\n",
    "    category_scene_dict=category_scene_dict,\n",
    "    aggregation_mode='sum')\n",
    "sum_argmax = np.argmax(sum_category_logits, axis=1)\n",
    "\n",
    "print(np.count_nonzero(mean_argmax - sum_argmax))\n",
    "print(np.count_nonzero(mean_argmax - val_predictions))\n",
    "print(np.count_nonzero(sum_argmax - val_predictions))\n",
    "\n",
    "print(mean_argmax[:5], val_predictions[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-correlation",
   "language": "python",
   "name": "model-correlation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
